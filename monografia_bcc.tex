% Modelo de TCC do Bacharelado em Ciência da Computação da UNIFESP 
% Baseado no Modelo de Documentos Academicos do ABNTex2  

\documentclass[	12pt, Times, openright, twoside, a4paper, english, brazil]{abntex2}

% ---
% Pacotes fundamentais 
  \usepackage{cmap}				% Mapear caracteres especiais no PDF
  %\usepackage{lmodern}			% Usa a fonte Latin Modern	
  \usepackage{times}
  \usepackage[T1]{fontenc}			% Selecao de codigos de fonte.
  \usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
  \usepackage{lastpage}			% Usado pela Ficha catalográfica
  %\usepackage{natbib}
  \usepackage{indentfirst}			% Indenta o primeiro parágrafo de cada seção.
  \usepackage{color,xcolor}				% Controle das cores
  \usepackage{graphicx}			% Inclusão de gráficos
  % ---
  \usepackage[portuguese, ruled, linesnumbered]{algorithm2e} %Peseudocodigo
  \usepackage{amssymb} %checkmarker
% ---
% Pacotes de citações
% ---
  \usepackage[brazilian,hyperpageref]{backref}	 % Paginas com as citações na bibl
  \usepackage[alf]{abntex2cite}	% Citações padrão ABNT
  \usepackage{datatool}
  
  
  \usepackage{booktabs} % For \toprule, \midrule and \bottomrule
  \usepackage{siunitx} % Formats the units and values
  \usepackage{pgfplotstable} % Generates table from .csv
  \usepackage{hyperref}
    \hypersetup{
        colorlinks=true,
        linkcolor=blue,
        filecolor=magenta,      
        urlcolor=cyan,
    }

    \urlstyle{same}
      \usepackage{listings}
      \usepackage{color}
 
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{
  language=Python,                
  basicstyle=\footnotesize,           
  numbers=left,                   
  numberstyle=\tiny\color{gray},  
  stepnumber=2,                             
  numbersep=5pt,                  
  backgroundcolor=\color{white},    
  showspaces=false,               
  showstringspaces=false,         
  showtabs=false,                 
  frame=single,                   
  rulecolor=\color{black},        
  tabsize=2,                      
  captionpos=b,                   
  breaklines=true,                
  breakatwhitespace=false,        
  title=\lstname,                               
  keywordstyle=\color{blue},          
  commentstyle=\color{dkgreen},       
  stringstyle=\color{mauve},     
}
% --- 
% CONFIGURAÇÕES DE PACOTES
% --- 
% Setup siunitx:
\sisetup{
  round-mode          = places, % Rounds numbers
  round-precision     = 2, % to 2 places
}

% ---
% Configurações do pacote backref
% Usado sem a opção hyperpageref de backref
 % \renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
  % Texto padrão antes do número das páginas
%  \renewcommand{\backref}{}
  % Define os textos da citação
%  \renewcommand*{\backrefalt}[4]{
%  	\ifcase #1 %
% 		Nenhuma citação no texto.%
%  	\or
 % 		Citado na página #2.%
%  	\else
%  		Citado #1 vezes nas páginas #2.%
%  	\fi}%
  % ---

  % numeração de figuras e elas 
  \counterwithout{figure}{section}
  \counterwithout{table}{section}

  %\renewcommand\tablename{Tabela{\arabic{chapter}.}}


% ---
% Informações de dados para CAPA e FOLHA DE ROSTO
% ---
  \titulo{ANÁLISE DE DEMANDA DO RESTAURANTE UNIVERSITÁRIO DO I.C.T UNIFESP VIA REDES NEURAIS}
  \autor{Douglas Diniz Landim}
  \local{São José dos Campos, SP}
  \data{Outubro de 2020}
  \orientador{Prof. Dr. Marcos Gonçalves Quiles}
  %\coorientador{Prof. Dr. }
  \instituicao{%
    Universidade Federal de São Paulo -- UNIFESP
    \par
    Instituto de Ciência de Tecnologia
    \par
    Bacharelado em Ciência da Computação}
  \tipotrabalho{Trabalho de Graduação}
  % O preambulo deve conter o tipo do trabalho, o objetivo, 
  % o nome da instituição e a área de concentração 
  \preambulo{Trabalho de conclusão de curso apresentado ao Instituto de Ciência e Tecnologia – UNIFESP, como parte das atividades para obtenção do título de Bacharel em Ciência da Computação.}
  % ---

% informações do PDF
  \makeatletter
  \hypersetup{
       	%pagebackref=true,
  		pdftitle={\@title}, 
  		pdfauthor={\@author},
      	pdfsubject={\imprimirpreambulo},
  	    pdfcreator={LaTeX with abnTeX2},
  		pdfkeywords={abnt}{latex}{abntex}{abntex2}{trabalho acadêmico}, 
  		colorlinks=true,       		% false: boxed links; true: colored links
      	linkcolor=blue,          	% color of internal links
      	citecolor=blue,        		% color of links to bibliography
      	filecolor=magenta,      		% color of file links
  		urlcolor=blue,
  		bookmarksdepth=4
  }

  \makeatother
% --- 
% --- 
% Espaçamentos entre linhas e parágrafos 
% --- 
% O tamanho do parágrafo é dado por:
  \setlength{\parindent}{1.3cm}
  % Controle do espaçamento entre um parágrafo e outro:
  \setlength{\parskip}{0.2cm}  % tente também \onelineskip
  % ---

  % compila o indice
  % ---
  \makeindex
  % ---

% ----
% Início do documento
% ----
\begin{document}
  % Retira espaço extra obsoleto entre as frases.
  \frenchspacing 

  % ----------------------------------------------------------
  % ELEMENTOS PRÉ-TEXTUAIS
  % ----------------------------------------------------------
  % \pretextual

  % ---
  % Capa
  % ---
    \begin{capa}
      \begin{center}
       \includegraphics[width=.25\textwidth]{logo-unifesp.pdf}
        \vspace*{\fill}
        
        {\ABNTEXchapterfont\large\imprimirautor}
        \vspace*{\fill}
        
        {\ABNTEXchapterfont\bfseries\Large\imprimirtitulo}
        \vspace*{\fill}\vspace*{\fill}
        
       \imprimirlocal
       \end{center}
    \end{capa}

  % ---
  % Folha de rosto
  % (o * indica que haverá a ficha bibliográfica)
  % ---
    \imprimirfolhaderosto*
  % ---

  % ---
  % Inserir folha de aprovação
  % ---
  % Isto é um exemplo de Folha de aprovação, elemento obrigatório da NBR
  % 14724/2011 (seção 4.2.1.3). Você pode utilizar este modelo até a aprovação
  % do trabalho. Após isso, substitua todo o conteúdo deste arquivo por uma
  % imagem da página assinada pela banca com o comando abaixo:
  %
  % \includepdf{folhadeaprovacao_final.pdf}
  %
    \begin{folhadeaprovacao}
      \begin{center}
        {\ABNTEXchapterfont\large\imprimirautor}

        \vspace*{\fill}\vspace*{\fill}
        {\ABNTEXchapterfont\bfseries\Large\imprimirtitulo}
        \vspace*{\fill}
        
        \hspace{.45\textwidth}
        \begin{minipage}{.5\textwidth}
            \imprimirpreambulo
        \end{minipage}%
        \vspace*{\fill}
       \end{center}
        
       Trabalho para apresentar em DEZEMBRO/2018:

       \assinatura{\textbf{\imprimirorientador} \\ Orientador} 
       \assinatura{\textbf{Professor} \\ Convidado 1}
       \assinatura{\textbf{Professor} \\ Convidado 2}
       \assinatura{\textbf{Professor} \\ Convidado 3}
       %\assinatura{\textbf{Professor} \\ Convidado 4}
          
       \begin{center}
        \vspace*{0.5cm}
        {\large\imprimirlocal}
        \par
        {\large\imprimirdata}
        \vspace*{1cm}
      \end{center}
      
    \end{folhadeaprovacao}
  % ---

  % ---
  % Dedicatória
  % ---
    \begin{dedicatoria}
       \vspace*{\fill}
       \centering
       \noindent
       \textit{ Este trabalho é dedicado aos meus pais que apoiaram e sacrificaram esforços para me manter ativo nessa jornada, a todos os professores que me somaram conhecimentos, oportunidades e esperanças indo além de suas rotinas e agendas em prol do ensino, e principalmente à todos que me motivaram me oferecendo desafios para que eu pudesse enfrentá-los superando meus próprios limites } \vspace*{\fill}
    \end{dedicatoria}
  % ---

  % ---
  % Agradecimentos
  % ---
    \begin{agradecimentos}
        \paragraph{Minha Jornada}
        Minha jornada pela graduação foi marcada por muita persistência, dificuldades e fracassos. Agradeço primeiramente a Deus por me dar fé e alimentar minha persistência e esperança. Apesar de todo o conteúdo técnico das mais de 40 disciplinas do meu curso, o que mais me agregou aprendizado foi o ambiente desafiador desta universidade; que somado à muitas dificuldades pessoais, acidentes, contra-tempos de saúde, profissão e família; constituiu o conjunto perfeito de desafios que me transformou em uma pessoa forte e destemida para enfrentar as cobranças do mercado, mais convicto e perseverante a cada nova tentativa de conquistar meus objetivos. Agradeço à minha família por sempre me apoiar dando tudo de si, aos meus professores que me orientaram e me motivaram, nas reuniões e chats online até nos finais de semana, aos amigos universitários, e a todos os professores que me acompanharam e ofereceram desafios em todos esses anos na UNIFESP.
        \paragraph{Dedicatórias}
                
                À professora Daniela Musa por ser minha primeira coordenadora de curso e orientadora quando ingressei na Unifesp\newline
                
                Aos professores das disciplinas que formaram minha base de conhecimento da ciência da computação e que me deram grande preparo para as minhas atividades acadêmicas, profissionais e nos diversos processos seletivos que participei no mercado. Aos professores Reginaldo, Bruno Kimura, Àlvaro Fazenda, Regina Coelho, Arlindo Flavio, Ana Luiza e Otavio Lemos.\newline
                
                À professora Camila Bertini  que na disciplina de simulação de sistemas me motivou nos primeiros estudos no tema deste trabalho, com uma realização de correlação com reamostragem de consumo x temperatura em 2016.\newline
                
                À professora Flavia Martins de estatística, que me orientou algumas vezes em sua sala sobre a introdução teórica de predições com redes neurais, sua tese de doutorado foi bem complementar e enriquecedora na fundamentação teórica deste trabalho.\newline
                
                Aos professores Vinicius Veloso e Fabio Faria, por me apresentarem a disciplina de inteligencia artificial. E ao Vinicius Veloso por me orientar na primeira parte deste trabalho e em todo o desenvolvimento de fundamentação teórica da primeira parte.\newline
                
                Ao professor Marcos Quiles por me orientar nesta segunda parte do trabalho, me apresentando desde o início o trabalho com python, tensorflow, scikit learning, sobre as orientações mais específicas do aprendizado da rede neural como uma regressão em um hiperplano. Em me orientar nas métricas de avaliação dos modelos e sobre a toda a metodologia experimental.\newline
                
                À equipe de Data Science e Machine Learning engineering da empresa 2RP-NET, especialista em análise de dados e aprendizado de máquina em Big-data, da qual recentemente fui integrado em setembro/2020 graças ao aprendizado adquirido neste trabalho acadêmico. E por ter disponibilizado um período extenso da reunião de equipe durante o nosso expediente para discutirmos os resultados e métricas deste trabalho, equipe da qual é composta por profissionais mestres e doutores em data science e machine learning.\newline
                
                À todos os outros professores, colegas, alunos e colaboradores do instituto de ciência e tecnologia da UNIFESP.\newline
                
                À minha família por ter me apoiado nesse longo período na UNIFESP.\newline

    \end{agradecimentos}
  % ---

  % ---
  % Epígrafe
  % ---
    \begin{epigrafe}
        \vspace*{\fill}
    	\begin{flushright}
    		\textit{Mesmo desacreditado e ignorado por todos, não posso desistir, pois para mim, vencer é nunca desistir.\\
    		(Albert Einstein)}
    	\end{flushright}
    \end{epigrafe}
  % ---

  % ---
  % RESUMOS
  % ---

  % resumo em português
    \begin{resumo}
         O presente trabalho tem como objetivo o estudo de métodos para a previsão de vendas do restaurante universitário da Unifesp para evitar super-projeção de demanda com consequência de desperdício de alimentos, ou subprojeção com consequência de docentes ou discentes sem refeições.
         Em uma investigação anterior, realizada como trabalho de disciplina, o autor deste trabalho empregou métodos estatísticos para a construção do modelo de previsão. Neste trabalho, será empregado um método de aprendizado de máquina, mais especificamente, uma rede neural artificial do tipo Perceptron de Múltiplas Camadas. Na investigação anterior, verificou-se que a temperatura da região onde se localiza o campus do restaurante foi analisada por recorrência via \textit{bootstrap} como um fator que exerce impacto sobre as vendas do restaurante em certos períodos do semestre. Assim,  neste trabalho de conclusão de curso serão obtidas novas variáveis e um intervalo maior de amostragem na análise da previsão de demanda.
 
    %O presente trabalho tem como objetivo a comparação com o método de análise da previsão de vendas do restaurante universitário da Unifesp, previamente feito pelo autor deste trabalho com aplicação de métodos estatísticos, e atualmente com métodos de aprendizado de máquina. Tal análise por aprendizado de máquina foi apontado como relevante solução no fim da análise estatística do trabalho anterior. A temperatura da região onde se localiza o campus do restaurante foi analisada por recorrência via bootstrap como um fator que exerce impacto sobre as vendas do restaurante em certos períodos do semestre, e neste trabalho de conclusão de curso serão obtidas novas variáveis e um intervalo maior de amostragem na análise da previsão de demanda de refeições do restaurante em um novo modelo com aprendizado de máquina a fim de que seja obtido um modelo de previsão viável para evitar super-projeção de demanda com consequência de desperdício de alimentos, ou subprojeção com consequência de docentes ou discentes sem refeições.
     
     \vspace{\onelineskip}
        
     \noindent
     \textbf{Palavras-chave}: Redes Neurais Artificiais, Previsão de demanda, Aprendizado de Máquina, Inteligência Artificial, Perceptron Múltiplas camadas. 
     
    \end{resumo}

  % resumo em inglês
    \begin{resumo}[Abstract]
     \begin{otherlanguage*}{english}

% TRADUZIR NOVAMENTE DO RESUMO ALTERADO

        This work has the objective of studying methods to forecast meals demand on Unifesp's university restaurant to avoid overprojection of demand as a result of food wastage, or underproduction with the consequence of teachers or students without meals.
        In an earlier research, carried out as a discipline work, the author of this paper used statistical methods for the construction of the prediction model. In this work, a machine learning method will be employed, more specifically, an artificial neural network of the Perceptron type of Multiple Layers. In the previous investigation, it was verified that the temperature of the region where the restaurant's campus is located was analyzed by recurrence via bootstrap as a factor that has an impact on restaurant sales in certain periods of the semester. Thus, in this work of conclusion of course will be obtained new variables and a greater interval of sampling in the analysis of the forecast of demand.

       \vspace{\onelineskip}
     
       \noindent 
       \textbf{Keywords}: Artificial Neural Networks, Demand Prediction, Machine Learning, Artificial intelligence, Perceptron Multiple layers.
     \end{otherlanguage*}
    \end{resumo}

  % ---
  % inserir lista de ilustrações
  % ---
    \pdfbookmark[0]{\listfigurename}{lof}
    \listoffigures*
    \cleardoublepage
  % ---

  % ---
  % inserir lista de tabelas
  % ---
    \pdfbookmark[0]{\listtablename}{lot}
    \listoftables*
    \cleardoublepage
  % ---

  % ---
  % inserir lista de abreviaturas e siglas
  % ---
    \begin{siglas}
    \item[ICT] Instituto Central de Tecnologia
    \item[R.U.] Restaurante Universitário
    \item[UNIFESP] Universidade Federal de São Paulo
    \item[UFV] Universidade Federal de Viçosa
    \item[UNESP] Universidade Estadual Paulista Júlio de Mesquita Filho
    \item[BDMEP] Banco de Dados Meteorológicos para Ensino e Pesquisa
    \item[RNA] Rede Neural Artificial
    \item[PMC] Perceptron de Múltiplas Camadas

    \end{siglas}
  % ---

  % ---
  % inserir lista de símbolos
  % ---
  %\begin{simbolos}
  %  \item[$ \Gamma $] Letra grega Gama
  %  \item[$ \Lambda $] Lambda
  %  \item[$ \zeta $] Letra grega minúscula zeta
  %  \item[$ \in $] Pertence
  %\end{simbolos}
  % ---

  % ---
  % inserir o sumario
  % ---
    \pdfbookmark[0]{\contentsname}{toc}
    \tableofcontents*
    \cleardoublepage
  % ---

  % ----------------------------------------------------------
  % ELEMENTOS TEXTUAIS
  % ----------------------------------------------------------
  \textual

  % ----------------------------------------------------------
  % CAPÍTULO 1 - Introdução
  % ----------------------------------------------------------
  \chapter{Introdução}
      \section{Contextualização e Motivação}

        \noindent 
        A previsão da demanda é o fator principal da eficiência de qualquer modelo de processamento do tipo entrada-saída, onde a sua saída deve atender uma demanda não determinística. É necessário prever a demanda para projetar e aperfeiçoar o processamento e a entrada deste modelo. 
        Portanto, a previsão de demanda é um ponto de extrema importância para qualquer empresa e, sendo adequada, permite o ajuste de todo o mecanismo de operações da empresa para atendê-la com a melhor eficiência possível, maximizando lucros, minimizando perdas e, principalmente, atendendo todas as necessidades do cliente.
        

        Todo restaurante universitário enfrenta problemas de previsão de demanda de refeições e prejuízos com a falta de vendas e ou o descarte de refeições não vendidas. Um dos grandes problemas enfrentados hoje no mundo é a elevação dos preços dos alimentos. O valor, além de monetário, é moral pois a alimentação é o recurso primitivo de base da humanidade que hoje ainda enfrenta um difícil acesso a este em muitas regiões carentes. O descarte de alimentos, provocado por suas limitações e durabilidade, também afeta o meio-ambiente. Isso tem causado preocupações para a população em geral e também para empresas como restaurantes que sofrem diretamente os reflexos da variação no preço dos alimentos e na demanda. Atualmente, o restaurante universitário do ICT - UNIFESP não possui um sistema que ajude na gestão de compras dos alimentos e sofre dos problemas acima relatados.

        No restaurante universitário do ICT - UNIFESP, as refeições são fornecidas de segunda a sexta-feira. O caso particular de restaurantes universitários envolve um fluxo de demanda influenciado pelo dia da semana, visto que a demanda é influenciada pela quantia de alunos presentes na universidade, que por sua vez é influenciada pela grade de aulas determinada semestralmente por dia da semana. 
%FIXED-T: PORTANTO APOS REFEIÇÕES AO PUBLICO DO CAMPUS...
        
        Devido às condições burocráticas no ambiente do restaurante que compreendem fidelidade de contrato e exclusividade, pois o restaurante se encontra em localização que o faz ser o único provedor de refeições ao público do campus 
        %, visto que este está isolado fisicamente de qualquer região comercial, e acessibilidade do público à aquisição de refeições que em sua maior parte adquirem refeições pelo valor de 2,50 sendo o restante do custo da refeição subsidiada pela instituição através de verbas federais, 
        .Portanto, a escolha dos parâmetros não será influenciada por muitos fatores externos como concorrência, acessibilidade do ponto, entre outros.

        Outro ponto importante é a obtenção dos valores de venda; não foram escolhidas as vendas diretas do ponto de venda de tickets de refeição, e sim os dados de coleta da entrada do restaurante, que demonstram a real movimentação de público no restaurante em determinado dia.

        O estudo da relação de vendas, temperatura, outras variáveis climáticas e do ambiente, já é comum em outros cenários; dentre eles, o de maior destaque é na demanda de energia elétrica. Os cenários de vendas de alimentos perecíveis ganha também destaque apesar de se encontrar investimentos maiores de previsão de demanda na indústria de produção de energia elétrica. O objetivo, tanto no cenário deste trabalho - o restaurante universitário, como em outros cenários é o mesmo: atender toda a demanda de consumo e evitar transtorno a qualquer consumidor pela falta do produto desejado e evitar prejuízos de produção não consumida. Tais prejuízos impactam não só o fornecedor, mas o consumidor, visto que um fornecimento de produto e serviço com um bom planejamento de demanda poupa recursos ao produtor. Tais recursos podem ser investidos em melhor qualidade de produto e menor preço ao consumidor caso seja obtido um modelo de previsão viável para evitar sobrestimação de demanda com consequência de desperdício de alimentos, ou subestimação com consequência de docentes ou discentes sem refeições. 

        Tal problema tem sido impactante e frequente para o restaurante que informa que em alguns
        dias no mês passa por sobrestimação e desperdício superior a 30\% do total produzido.

        O modelo a ser analisado neste trabalho é o comportamento dos consumidores de um restaurante universitário (R.U), o qual precisa projetar sua compra de insumos e alocação de recursos na entrada de seu modelo de negócio, e projetar sua saída, que é a produção de refeições em quantidade numérica e inteira distribuída em função do tempo em dias. O consumo feito por alunos não se comporta de maneira determinística, já que este consumo é facultativo. Portanto, nem todos os alunos que estão na universidade se alimentarão no R.U. todos os dias.

        De acordo com o contrato presente entre o R.U e a universidade, o mesmo deve atender totalmente à demanda do público, sendo multado se caso algum consumidor fique sem alimentação. Porém, este mesmo contrato não trata refeições que não são consumidas; logo, o R.U. deve lidar integralmente o prejuízo de refeições produzidas acima da demanda de consumo. O que o R.U. faz com essas sobras está fora do escopo deste trabalho.

        Tais refeições fornecidas aos alunos são, em parte, subsidiadas pela universidade. O período de dados obtido para este trabalho compreende até Agosto de 2018 e segue um modelo de contrato antigo no qual o restaurante recebe R\$2,50 do aluno e R\$9,14 da universidade totalizando R\$11,64 por refeição.

        De agosto em diante, iniciando no segundo semestre de 2018, a universidade subsidia R\$5,44 da refeição do aluno e o mesmo R\$2,50, o R.U. recebe o total de R\$7,94. Logo, esta previsão de demanda corresponde também aos interesses da administração do campus local, que periodicamente deve realizar uma alocação de recursos financeiros para subsidiar todas estas refeições consumidas.

        É necessário então entender e descobrir quais elementos influenciam este consumo humano, de que forma estes elementos exercem tal influência e em qual intensidade ela ocorre.

        E para explorar tais elementos, é necessário explorar como este consumo ocorreu historicamente a fim de se encontrar padrões de comportamento, que no cenário deste trabalho acontece com informações distribuídas através do tempo. 

        Neste capítulo o principal objetivo é definir todos os conceitos que serão necessários para o entendimento total deste trabalho, analisando a forma que os dados são entendidos, e as ferramentas com os quais possam ser trabalhados.        

      \section{Definição do problema}
        O problema a definir neste trabalho é encontrar um modelo de previsão de demanda por meio de algoritmos de regressão via aprendizado de máquina.

      \section{Justificativas}
        As atuais abordagens de previsão do restaurante universitário, que envolvem análise exploratória semanal e dedução subjetiva pelos responsáveis pelo restaurante são falhas por não serem calculadas considerando-se uma visão ampla de todo um histórico de dados de grande amostragem. Além disso, não cruzam outras informações como dados climáticos, dados de calendário anual, feriados próximos, dentre outros. Essas falhas causam desperdício de alimentos por super-estimação de demanda e prejuízo de refeições descartadas, e falta de atendimento por sub-estimação de demanda de consumo.

      \section{Objetivos}
        \subsection{Objetivo geral}
          Construir um modelo utilizando uma Rede Neural Artificial para a previsão da demanda de
          refeições do restaurante universitário do ICT-UNIFESP com menos de 10\% de erro.
        
        \subsection{Objetivos específicos}
          \begin{itemize}
          \item Construir dois modelos utilizando algoritmos de regressão, por métodos estatísticos e de aprendizado de máquina; 
          \item Realizar análise e comparação da qualidade dos modelos; %XXX SE VAI FAZER OS DOIS, PRECISA MUDAR O TÍTULO, RESUMO, INTRO...
          \end{itemize}
%TODO-T: REVER METODOLOGIA
      \section{Metodologia}
        \paragraph*{Análise de regressão}

          Por se tratar de um trabalho de previsão de demanda,  este trabalho irá realizar a coleta e tratamento dos dados de consumo do restaurante universitário da Unifesp, a coleta de dados climáticos que influenciam em tal demanda, calcular os dados de calendário derivados das datas de coleta, por exemplo, o dia da semana, a estação do ano, o número do semestre (se par ou ímpar), horário, etc.

          Após a estruturação dos dados, será realizada uma análise exploratória fundamentada por \cite{Junior2007}, Capítulo 2.4, para previsões de demanda em geral.
          O modelo de dados de venda estruturados receberá o acréscimo de dados de variáveis climáticas, como possíveis fatores de influencia no consumo, conforme ocorre no trabalho de previsão de demanda de energia elétrica fundamentado por \cite{Almeida2013,RUAS2012,Silva2010}.

          Os trabalhos de \cite{Junior2007} e \cite{Silva2010} fundamentam também uma classificação de análises dos dados estruturados indicando os métodos de previsão de demanda para este modelo quantitavo que são a Regressão Linear Múltipla e RNAs.

          Assim, a primeira investigação usará a análise estatística de regressão linear múltipla fundamentada por \cite{Clarice2011} para se obter um modelo de previsão de demanda do R.U. do ICT-UNIFESP.

        \paragraph*{Estudo de Aprendizado de máquina}
          As análises de inteligência artificial, fundamentadas por trabalhos de previsão de demanda em R.U. da Universidade Federal de Viçosa, de acordo \cite{Lopes2008} e na Universidade Estadual Paulista Júlio de Mesquita por \cite{Rocha2011}, concluem a segunda aplicação da técnica de redes neurais artificiais com o método de Perceptron de Múltiplas Camadas (PMC) fundamentado em \cite{Haykin1994}, incrementando-se na técnica a inclusão de variáveis climáticas utilizadas nos trabalhos de previsão de  \cite{Almeida2013, RUAS2012, Silva2010}, modificando a topologia como em \cite{Lopes2008} para receber tais dados. 

          Após a modificação da topologia, os dados serão estruturados com a retirada de amostras aleatórias de validação e será construído um comitê de PMCs usando a média aritmética como agregador para a estimação.

        % \paragraph*{Meta-análise}
        %   De acordo com \cite{Flavia2014} que realiza um trabalho de previsão de consumo em aves, a técnica de meta-análise, a análise das análises, 
        
        %TODO : VERIFICAR OS INDICES
        \paragraph*{Análise dos resultados}
        De acordo com \cite{Flavia2014}, a comparação e a discussão dos resultados deve ser feita com base em medidas de avaliação de erro absoluto médio (EAM), erro quadrado médio (EQM) e raiz do erro quadrado médio (REQM).

      \section{Organização do documento}
        Este trabalho está organizado da seguinte maneira: o Capítulo 2 possui os conceitos básicos para o entendimento do trabalho. No Capítulo 3, apresenta-se alguns trabalhos relacionados. O Capítulo 4 contém o plano de atividades para o TCC II. A conclusão é apresentada no Capítulo 5.
  % ----------------------------------------------------------
  % CAPÍTULO 2 - Fundamentação Teórica
  % ----------------------------------------------------------
  \chapter{Fundamentação Teórica}
      % ----------------------------------------------------------
      % INTRODUÇÃO
      % ----------------------------------------------------------
    %   \section{Introdução}
        % A previsão da demanda é o fator principal da eficiência de qualquer modelo de processamento do tipo entrada-saída, onde a sua saída deve atender uma demanda não determinística. É necessário prever a demanda para projetar e aperfeiçoar o processamento e a entrada deste modelo. 

        % O modelo a ser analisado neste trabalho é o comportamento dos consumidores de um restaurante universitário, onde o mesmo precisa projetar sua compra de insumos e alocação de recursos na entrada de seu modelo de negócio, e projetar sua saída, que é a produção de refeições em quantidade numérica e inteira distribuída em função do tempo em dias, para atender um consumo feito por alunos, que não se comporta de maneira determinística, já que este consumo é facultativo aos alunos.

        % De acordo com o contrato presente entre o restaurante e a universidade, o mesmo deve atender totalmente à demanda do público, sendo multado se caso algum consumidor fique sem alimentação, porém este mesmo contrato não trata refeições que não são consumidas, logo o restaurante deve lidar integralmente o prejuízo de refeições produzidas acima da demanda de consumo.

        % Tais refeições fornecidas à alunos também são em parte subsidiadas pela universidade. O periodo que se compreende à agosto de 2018 segue um modelo de contrato antigo no qual o restaurante recebe R\$2,50 do aluno e R\$9,14 da universidade compreendendo o total de R\$11,64 por refeição.

        % De agosto em diante, iniciando no segundo semestre de 2018, a universidade subsidia R\$5,44 da refeição do aluno e o mesmo R\$2,50, o restaurante recebe o total de R\$7,94. Logo esta previsão de demanda corresponde também aos interesses da administração do campus local, que periodicamente deve realizar uma alocação de recursos financeiros para subsidiar todas estas refeições consumidas.

        % É necessário então entender e descobrir quais elementos influenciam este consumo humano, de que forma estes elementos exercem tal influência e em qual intensidade ela ocorre.

        % E para explorar tais elementos, é necessário explorar como este consumo ocorreu historicamente a fim de se encontrar padrões de comportamento, que no cenário deste trabalho acontece com informações distribuídas através do tempo. 

        % Neste capítulo o principal objetivo é definir todos os conceitos que serão necessários para o entendimento total deste trabalho, analisando a forma que os dados são entendidos, e as ferramentas com os quais possam ser trabalhados.

      % ----------------------------------------------------------
      % ESTATÍSTICA
      % ----------------------------------------------------------
      \section{Análises Estatísticas}
        \subsection{Análise Exploratória dos Dados}
          \cite{Junior2007} Cita que dados coletados em modelos de previsão possuem informações que quando são projetadas graficamente evidenciam comportamentos que em alguns casos podem ser visualizados e generalizados de forma subjetiva pelos gestores dos dados.  
          Em todos os casos, a análise exploratória é necessária para selecionar o melhor método de análise que se enquadra neste comportamento.

          Somente a análise exploratória não é o suficiente e realizada nos intervalos ou critérios incorretos pode comprometer seriamente as conclusões do comportamento dos dados, e que por sua vez pode comprometer seriamente a decisão dos gestores responsáveis por estes dados, no cenário de uma previsão de demanda. 
          Isto ocorre atualmente no cenário de previsão da demanda de refeições do ICT-UNIFESP, onde a universidade e o estabelecimento que fornece as refeições não tem nenhum modelo de previsão de demanda. 

          De acordo com o gestor da atual empresa que fornece refeições no ICT, a análise utilizada para se prever as refeições é observar dentro da semana o dia anterior de consumo. Em variações de 300 para 450 refeições aproximadamente, isso tem provocado um desperdício médio de 150 refeições diárias. Em geral, de acordo com o restaurante, todos os dias o mesmo trabalha com um erro e um descarte de 30\% das refeições que são trazidas e consumidas ao campus. Estima-se então que no período de 2011 - 01/08/2018 os estabelecimentos tenham tido um prejuízo de R\$1.885.938,40, e de 30\% de R\$78.386,85 no atual período de 01/08/2018 - 31/10/2018 totalizando o montante  R\$1.964.325,25. Aproximadamente 2 milhões de reais em prejuízo acumulado desde 2011.

        \subsection{Métodos de Previsão} 

          \cite{Junior2007} Realiza uma revisão bibliográfica extensa abordando principais métodos de previsão de consumo sazonais, no cenário de uma indústria cosmética. Tais métodos estatísticos de previsão se dividem em 2 ramificações, sendo quantitativos ou qualitativos. Métodos qualitativos fazem um julgamento dos dados expostos sem um sistema de processamento analítico para se produzir novos modelos ou dados, eles são úteis para sistemas de agrupamento, clusterização ou classificação de dados, sem fornecer novas informações numéricas ou modelos preditivos.

          Métodos quantitativos que é o foco deste trabalho, são analíticos e se baseiam em um modelo matemático para realizar previsões. 

          Para realizar tais previsões os métodos quantitativos necessitam de um histórico de dados, para analisar padrões em seu comportamento e predizer o futuro que irá agir dentro deste padrão.

          Estes métodos se ramificam em 2 tipos, as séries temporais e os modelos causais.
          \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.65\textwidth]
          		{01-junior-metodos-quantitativos.png}
          	}
          	\caption{Tipos de métodos quantitativos Retirado de \cite{Junior2007}.\label{fig:metodosQuantitativos}}
          \end{figure}

        \subsection{Métodos de previsão de Demanda}
          O autor supracitado também referencia métodos estatísticos especialmente selecionados para uma previsão de demanda, com a atenção de que alguns métodos qualitativos foram criteriosamente selecionados para prever uma demanda industrial, onde geralmente são previstas pelos métodos quantitativos.

          O comportamento dos dados deste trabalho, apesar de ter uma distribuição de datas em função do tempo se classificando em um modelo de série temporal, assume-se a hipótese que tem tal comportamento impactado por relações causais com outras variáveis como recesso acadêmico, feriados, eventos, precipitações intensas que causam trânsito local e impactam na logística e frequência do público, entre outras variáveis de causas menos aparentes.

          \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.65\textwidth]
          		{02-junior-metodos-previsao-demanda.png}
          	}
          	\caption{Métodos de previsão de demanda \cite{Junior2007}.\label{fig:metodosPrevisaoDemanda}}
          \end{figure}

        \subsection{Séries Temporais}
          De acordo com  \cite{Morettin1987} uma série temporal é um conjunto de observações ordenadas em função do tempo, comumente iguais, apresentando uma dependência serial entre elas, sendo um dos objetivos do estudo de séries temporais, analisar e modelar essa dependência. Além disso, séries temporais são analisadas pelos seus principais movimentos, como tendência, sazonalidade e a componente aleatória, sendo a tendencia e sazonalidade as propriedades que mais ganham destaque em pesquisas de previsão de demanda de carga elétrica. Os meios mais comuns de se analisar a componente sazonal são o Método de Regressão (paramétrico), Método de Médias Móveis (não paramétrico), e Método de Diferença Sazonal (sazonalidade determinística).  Neste trabalho, a distribuição dos dados do Restaurante se dá de forma paramétrica, ou seja, as vendas do restaurante se distribuem em função do tempo e com influências de parâmetros como o dia da semana por exemplo, sendo ideal as análises de regressão. 

          \cite{Almeida2013} também cita que para realizar a previsão de uma determinada série temporal é possível utilizar diferentes métodos. Pode-se classificá-los basicamente entre métodos estatísticos e baseados em inteligência artificial.
          Dentre os métodos estatísticos destacam-se:
          \begin{itemize}
          \item Regressão Linear Múltipla;
          \item Alisamento Exponencial;
          \item Média Móvel Integrada Auto-Regressiva (ARIMA)
          \end{itemize}
          Entre os métodos baseados em inteligência artificial tem-se:
          \begin{itemize}
          \item Redes Neurais Artificiais;
          \item Lógica Fuzzy.
          \end{itemize}

        \subsection{Componentes Temporais}

          É importante observar que os métodos de previsão em séries temporais buscam uma redução da série temporal à um modelo estacionário e a decomposição da série em componentes de tendência, ciclo, sazonalidade (próxima figura) e termo aleatório. A tendência entende-se pelo movimento persistente dos dados em uma direção, o ciclo indica o movimento oscilatório desta tendência, sazonalidade indica comportamento regular assumido de forma repetitiva e o termo aleatório se dá por movimentos irregulares presentes na série.
           
          As técnicas de previsão para evidências sazonais, conforme  usam métodos de regressão, que pode ser observados nos trabalhos de previsão de consumo de energia elétrica realizados por \cite{Almeida2013}, \cite{RUAS2012}, \cite{Silva2010} e de previsão de demanda de produtos cosméticos em \cite{Junior2007}

          O cenário deste estudo analisa a frequência de alunos dentro do ICT - UNIFESP e consequentemente dentro do R.U tem sazonalidade anual a partir do momento em que a grade de disciplinas tender a ter sazonalidade anual. \\

          \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.65\textwidth]
          		{03-ruas-serie-temporal-sazonal.png}
          	}
          	\caption{DADOS DE DEMANDA DE SAZONALIDADE DIÁRIA, EM FUNÇÃO DO HORÁRIO. Retirado de \cite{RUAS2012}.\label{fig:seriesTemporais}}
          \end{figure}

        \subsection{Previsão com Regressão Linear Múltipla}
          A teoria da regressão se iniciou no século XIX com Galton, que analisou a altura dos pais e dos filhos ($X_i$ e $Y_i$) e buscou a influencia da altura do pai no filho, notando que a altura do filho tendia à media da altura do pai, e chamou esta técnica de regressão pois existe uma tendência dos dados regredirem à média.

          \cite{Clarice2011} Informa que em estudos de regressão aplica-se o método relacionar uma variável aleatória Y com uma variável X, e no caso da regressão múltipla com múltiplas variáveis X, representando causas diferentes que se combinam para a ocorrência de um valor Y. 

          No exemplo abaixo de regressão linear simples, podemos analisar o total de venda Y de um dia X, sendo relacionado nas variações $(\beta_0, \beta_1, ..., \beta_k)$ de datas de $X$.

          Ou seja, $X,Y \rightarrow Y \simeq f(X) $\\
          Na regressão simples $Y$ depende apenas de uma variável $X$, isto é, $Y \simeq f(\beta_0, \beta_1, ..., \beta_k) + E_y$, Sendo $E_y$ um erro aplicado à esta função para se chegar no valor $Y$. Logo a função $f(.)$ pode ser linear nos parâmetros $(\beta_0, \beta_1, ..., \beta_k)$, se a derivada da função em relação às derivadas dos parâmetros, corresponderem à $h(X),i$, para $i$ variando de $0$ à $k$. Sendo $h(X),$ dependente apenas de $X$.
          $\frac {\partial f}{\partial \beta_i} = h (X),i = 0,1,...,k $

          Na regressão múltipla, onde temos múltiplas relações causais $X_1$ à $X_k$, em ocorrências $\beta_0$ à $\beta_k$, temos a função: $Y \simeq f(X_1, X_2, ..., X_k, \beta_0, \beta_1, ..., \beta_k) + E_y$. Também sendo linear nos parâmetros se a derivada da função em relação às múltiplas derivadas dos parâmetros, corresponderem à $h(X_1,X_2,...,X_k)$, tendo $h(.),$ dependente apenas de $X_1,X_2,...,X k$. Em caso contrário, $f(.)$ é uma função não linear dos parâmetros.

          Logo, $Y=f(X_1,X_2,...,X_k,\beta_0,\beta_1,...,\beta_k)+E y$ é linear nos parâmetros se:
          $\frac {\partial f}{\partial \beta_i} = h(X_1,X_2,...,X_k)$
          
          \paragraph{Representação dos dados}
          Na tabela abaixo representa-se a estrutura de dados para regressão linear múltipla, com n observações da variável resposta $Y$ e $p$ variáveis explicativas. Assim, $y_i$ é o valor da i-ésima resposta e $x_{ij}$ na é o valor da variável $x_j$ do conjunto de $j$ variáveis correspondente à resposta $y_i$ .
          Para que seja possível aplicar o método dos quadrados mínimos (explicado adiante) de resolução do sistema de variáveis $X$ em relação à $Y$, é importante que se obtenha p observações $Y$, onde $n\geq (p+1)$.
          
          \begin{table}[!ht]
          	\centering
          		\caption{Representação de dados para regressão múltipla.}	\label{tab:regressaoMultiplaEstrutura}                  
          				\begin{tabular}{|c|c|c|c|c}          			
          				\hline $y$ & $x_1$ & $x_2$ & ... & $x_p$\\
                        \hline $y_1$ & $x_{11}$ & $x_{12}$ & ... & $x_{1p}$\\
                        \hline $y_2$ & $x_{21}$ & $x_{22}$ & ... & $x_{2p}$\\
                        \hline $\vdots$ & $\vdots$ & $\vdots$ & ... & $\vdots$\\
                        \hline $y_n$ & $x_{n1}$ & $x_{2n}$ & ... & $x_{np}$\\
          		\end{tabular}
          \end{table}
          Satisfazendo o modelo final $Y_i = \beta_0 + \beta_1*x_{i1} + \beta_2*x_{i2} + \beta_p*x_{ip} + \epsilon_i$\\
          $i=1,...,n$
          
          \paragraph{Método dos Mínimos Quadrados}
          O método dos mínimos quadrados, é uma técnica utilizada popularmente em estimações econômicas, que busca encontrar o melhor ajuste de um conkunto de ados conforme tabela e modelo acima, para minimizar a soma dos erros quadráticos $\epsilon$. A técnica foi publica por Adrien-Marie Legendre em 1809, em Nouvelles méthodes pour la détermination des orbites des comètes, realizando a hipótese de que a distribuição do $\epsilon$ seja aleatória e normal, embora tal dedução já existisse indiretamente nos teoremas de Gauss-Markov.
          
          A minimização da soma dos erros quadráticos busca então minimizar a seguinte equação $L$:
          
          $L = \sum_{i=1}^{n} \epsilon_i^2 = \sum_{i=1}^{n}(Y_i-\beta_0-\beta_1*x_{i1}-...-\beta_p*x_{ip})^2$
          
           A técnica segue o principio de ser linear nos parâmetros, já demonstrado acima conforme \cite{Clarice2011}.
           Logo deriva-se L em função dos parâmetros $\beta$.\\
           $\frac {\partial L}{\partial \beta_0} = -2 \sum_{i=1}^{n}[Y_i-\beta_0-\beta_1*x_{i1}-...-\beta_p*x_{ip}]$\\
           $\frac {\partial L}{\partial \beta_j} = -2 \sum_{i=1}^{n}[Y_i-\beta_0-\beta_1*x_{i1}-...-\beta_p*x_{ip}]x_{ji}$
          
          Aplicando-se álgebra, igualando as derivadas parciais a zero e organizando o sistema em forma matricial, o modelo final pode ser dado por: $Y=X\beta+\varepsilon$.
          
          $$Y=\left[\begin{array}{c}Y_1\\Y_2\\\vdots\\Y_n\\\end{array} \right]~~,~~X=\left[\begin{array}{ccccc}1~x_{11}~ x_{12}~\ldots~x_{1p}\\1~x_{21}~x_{22}~\ldots~x_{2p}\\\vdots~~~\vdots~~~\vdots~~~\ddots~~~\vdots\\1~x_{n1}~x_{n2}~\ldots~x_{np}\\\end{array} \right]~~,~~\beta=\left[ \begin{array}{c}\beta_0\\\beta_1\\\vdots\\\beta_p\\\end{array} \right]~~\mbox{e}~~ \varepsilon=\left[ \begin{array}{c}\varepsilon_1\\\varepsilon_2\\\vdots\\\varepsilon_n\\\end{array}\right],$$
          
          Logo, $$\frac{\partial L}{\partial\beta}=-2X^\prime Y+2X^\prime X\beta.$$
          
          Aplicando-se álgebra matricial, substituindo o vetor de coeficientes $\beta$ por $\widehat\beta$ que é o objetivo da relação busca entre as variáveis $X$ e $Y$:
          $\widehat{\beta}=(X^\prime X)^{-1} X^\prime Y$
          
          Portanto o modelo final é dado por $Y_{estimado} = X\widehat{\beta}$.
          
        \subsection{Algoritmo de Regressão Linear Multipla}
        
            \begin{enumerate}
                  \item Estruturação dos dados em forma matricial, $Y_{1,1...n}$ e $X_{1...n,1...j}$, sendo $n \geq (j+1)$ \\
                  \item Obtenção do vetor de coeficientes $\widehat{\beta}$ das variáveis $X$, através da operação $\widehat{\beta}=(X^\prime X)^{-1} X^\prime Y$
                  \item Construção do modelo final por $Y_{estimado} = X\widehat{\beta}$.
            \end{enumerate}
      % ----------------------------------------------------------
      % INTELIGENCIA ARTIFICIAL
      % ----------------------------------------------------------
      \section{Inteligencia Artificial}
        \paragraph*{A Inteligência artificial} "A inteligência artificial é o ramo da ciência da computação que se ocupa do comportamento inteligente." \cite{Luger2004}.
          O termo "Inteligencia Artificial" surgiu em meados de 1956 em uma conferência, chamada Dartmouth Summer Research Project on Artificial Intelligence, sediada nos Estados Unidos em Dartmouth College, Hanover, New Hampshire, a conferência foi organizada por John McCarthy e teve como proposta reunir matemáticos, cientistas da computação e pesquisadores buscando meios de como fazer com que as máquinas usem linguagem, abstrações de formulários e conceitos, para resolver problemas que eram reservados aos humanos, e que consigam melhorar o seu próprio desempenho.

          Sistemas de inteligência artificial buscam então resolver funções e problemas que seres humanos conseguem resolver melhor do que máquinas convecionais, usando sua capacidade de abstração e aprendizagem com o erro.

        \subsection{Neuronio Artificial}
         
          \paragraph*{História e inspiração da Inteligência Artificial}
            Redes Neurais Artificiais são elementos de inteligência artificial da ciência da computação, inspirados no funcionamento do cérebro humano.
            São formadas por neurônios artificiais interconectados que são capazes de processar múltiplos valores de entradas, e reagir produzido uma resposta relacionada à essas entradas.
            Como qualquer outro método de aprendizado de máquina, este modelo busca obter um aprendizado a partir dos dados de entrada recebidos, criando uma capacidade de generalização de problemas e assim buscam o objetivo principal de resolver novos problemas com este aprendizado.

            Uma rede neural pode não produzir uma resposta esperada, resolvendo erroneamente um problema, assim como o cérebro humano tem limitações de aprendizado, que levam o homem a cometer falhas de decisões ou ações por um aprendizado mal treinado. Por isso as características fundamentais que tornam uma rede neural artificial em uma boa solução, é um bom planejamento de sua topologia, e método de treinamento, que serão explicados a seguir.

            \cite{Muhammad2014} Demonstra em sua pesquisa que a propriedade fundamental do cérebro é a sua capacidade de mudar com uma grande variedade de experiências, inclusive lesões que provocam perdas de neurônios, abordando princípios de plasticidade cerebral, mostra também que a capacidade de aprendizado de mamíferos que sofreram uma redução de neurônios causada por lesões, pode ser restaurada não somente pela recuperação desses neurônios perdidos, mas sim por novas conexões e sinapses entre outros neurônios. Ou seja, a rede sofre uma mudança de topologia.

            \cite{Fapesp192} Mostra em um experimento recente que o cérebro humano possui atualmente 86 bilhões de neurônios interconectados, e que sua capacidade de aprendizado e habilidades evolutivas também vêm aumentando em conjunto com seu número de neurônios e topologia de rede neural, que há 30 milhões de anos atrás tinha apenas 2,5 bilhões de neurônios e era apenas um animal arborícola quadrúpede.
%TODO-T: FIGURA 4 ESTORANDO MARGEM DO TÍTULO
          \paragraph*{Neuronio Biológico}
            O modelo de neurônio artificial surge então, com a busca da inteligência artificial de reproduzir o comportamento de aprendizado humano, reproduzindo computacionalmente seu elemento biológico principal de aprendizagem: O neurônio biológico. 
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.65\textwidth]
                {05-neuronio.jpg}
              }
              \caption{Neuronio Biológico, retirado de https://pt.khanacademy.org/science/biology/human-biology/neuron-nervous-system/v/anatomy-of-a-neuron.\label{fig:NeuronioBiológico}}
            \end{figure}
            Um neurônio biológico (Figura 05) processa informações recebidas por meio de seus dentritos e processa-as em seu corpo celular, tal reação à esses estímulos recebidos gera um sínal de saída como resposta aos estímulos, enviado através do axônio. Esse estímulo é repassado como sinal de entrada, através de outros neurônios por meio de seus dendritos, e o ciclo se repete em uma vasta rede.
            Controlando essas conexões, pontos de contato entre a resposta de um neurônio e a entrada de outro, existem as sinapses. Elas funcionam como agentes que permitem a interação acontecer ou inibem, e são acionadas por um conjunto somatório de estímulos. Se tal somatório de estímulos for satisfatório, elas permite a transmissão de sinal elétrico pelo axônio até o dendrito de um neurônio vizinho, formando um ciclo de aprendizado em uma rede neural biológica.

          \paragraph*{Neuronio Artifical}
            Warren McCulloch e Walter Pitts em 1942 observando o neurônio biológico iniciam a busca de um modelo computacional do mesmo. McCuloch era psiquiatra e neuroanatomista e passou cerca de 20 anos refletindo e estudando sobre a representação do sistema nervoso, em 1942 ele convidou Pitts, que era matemático, para fazer parte das suas pesquisas.Em 1943 lançaram o artigo "A Logical Calculus of the Ideas Immanent in Nervous Activity." chegando em um modelo matemático do neurônio artificial: 

            \begin{figure}[!ht]
                \center{
                  \includegraphics[width=0.65\textwidth]
                  {06-neuronio-artificial.png}
                }
                \caption{Neuronio Artificial, Retirado de \url{http://redesneuraisartificiais.blogspot.com/2010/10/o-primeiro-modelo-de-um-neuronio-criado.html}\label{fig:NeuronioArtificial}}
            \end{figure}

            Assim como no neurônio biológico, este modelo reage à um vetor de entradas $X_0,X_1,...,X_n$ onde tem suas sinapses representadas por pesos numéricos, existe uma soma ponderada dessas entradas que é controlada por uma função de transferência ou função de ativação, determinando se essa soma é maior que um valor numérico. Se essa soma for satisfatória o neurônio é ativado emitindo um valor de saída 1, caso contrário se emite um valor de saída 0.
            Todo o funcionamento deste modelo então é reduzido a responder se a soma recebida é maior que um valor numérico esperado.

            Neste modelo simplista o neurônio consegue realizar operações lógicas. Na figura 07 os pesos w1 e w2 e o limiar T estão ajustados para responder à operação AND que resumidamente à uma operação lógica que somente produz um valor positivo 1 na resposta de saída se ambos os valores de entrada forem 1.
            %TODO-T: TÍTULO DA FIGURA ESTOURANDO A MARGEM
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.65\textwidth]
                {07-neuronio-operacao-and.png}
              }
              \caption{Neuronio Artificial - Operação AND, Retirado de http://redesneuraisartificiais.blogspot.com/2010/10/o-primeiro-modelo-de-um-neuronio-criado.html\label{fig:NeuronioArtificialAnd}}
            \end{figure}
%FIXED-T VIRGULA REMOVIDA DPS DE POSITIVO
           O neurônio irá comparar se a soma das entradas $X$ multiplicadas pelos seus devidos pesos $W$, será menor que o limiar T. Ele somente irá produzir uma resposta positiva (1) se essa soma for maior. É fácil verificar então na imagem, que o resultado dessa soma só será positivo  se ambas as entradas forem 1, onde a soma será $2>1,5$.

            \begin{table}[!ht]
            \centering
            \caption{Operação Lógica AND} \label{tab:and}
              \begin{tabular}{|c|c|c|}
                  \hline  \textbf{$X_1$} & \textbf{$X_2$} &  \textbf{Saída}\\
                  \hline 0 & 0 & 0\\
                  \hline 0 & 1 & 0\\
                  \hline 1 & 0 & 0\\
                  \hline 1 & 1 & 1\\
                  \hline 
              \end{tabular}
            \end{table}

        \subsection{Redes Neurais Artificiais}
          \paragraph*{Perceptron}
            O modelo de Warren McCulloch e Walter Pitts, apesar de conseguir simular o modelo de neurônio biológico e resolver algumas tarefas lógicas e matemáticas não atendia o objetivo principal da Inteligência Artificial: A capacidade de aprendizado.
            Para utilizar um modelo de neurônio artificial a fim da solução de um problema era necessário conhecer o ajuste dos pesos das entradas, e em uma tarefa de um cenário complexo e com muitas variáveis, ou pesos não perceptíveis ao valor esperado de saída, este ajuste não se torna trivial.
            
            Em 1958, o cientista da computação Frank Rosemblatt desenvolveu o modelo de neurônio artificial Perceptron para solucionar este problema de ajuste de pesos.
            Basicamente neste novo modelo, os pesos das conexões são ajustados de forma autônoma com a introdução de pessoas associados e uma valor bias, a fim de buscar um reconhecimento autônomo de padrões. Tarefas de reconhecimento de padrões simples com separações lineares os seres humanos conseguem realizar de forma trivial mas ainda era um desafio para tal problema se resolvido por uma máquina.

            O perceptron \cite{Flavia2014} possui apenas uma camada de entrada e saída, a saída utiliza como função de ativação a função degrau $u$ que define quando o neurônio emitirá o sinal lógico 1 ou quando emitirá o sinal lógico 0.

            O sinal de saída do perceptron entende-se então por:
            $y= \delta(\sum_{i=1}^{n}XiWi+b)$
            \begin{itemize}
            	\item $ Xi $ - sinais de entrada do neurônio;
            	\item $ Wi $ - pesos sinápticos do neurônio;
            	\item $ b $ - bias ou limiar de ativação;
            	\item $ \delta(.) $ - função de ativação;
            	\item $ y $ - sinal de saída do neurônio.
            \end{itemize}
			
            \begin{figure}[!ht]
            	\center{
              \includegraphics[width=0.65\textwidth]
              {08-perceptron.png}
            }
            \caption{Neuronio Artificial Perceptron, retirado de \cite{Junior2007} \cite{}\label{fig:perceptron}}
            \end{figure}
			
			     Em algumas literaturas o bias pode ser reduzido a um peso $W_0$ com entrada $X_0$ fixo em 1 no neurônio, a representação gráfica da topologia pode mudar, mas no somatório de saída, o calculo continua o mesmo.
			
			     A função de ativação $\delta$ se apresenta de forma linear ou não linear, determinando a saída de um neurônio a partir do seu potencial de ativação. 
			     As funções de ativação podem ser observadas na figura 09, sendo a de maior popularidade de utilização, a sigmoide.
			
			     \begin{figure}[!ht]
    				\center{
    					\includegraphics[width=0.80\textwidth]
    					{09-delta.png}
    				}
    				\caption{Funções de Ativação retirado de \cite{Flavia2014} \label{fig:perceptron2}}
			     \end{figure}
			
				    As funções de ativação dá a capacidade do perceptron quando conectado em rede (explicado no próximo capítulo) de resolver problemas lineares e não lineares, agregando adaptação e improviso ao resolver programas que não estão contidos em seus dados de alimentação.
			
		      \paragraph*{Perceptron - Treino Supervisionado}
            \cite{Almeida2013} cita que o processo de aprendizado do perceptron pode ocorrer de forma supervisionada quando o neurônio deve aprender a relacionar um conjunto observado de variáveis à um valor observado de saída deste mesmo conjunto. O neurônio recebe os sinais de entrada $Xi$ e produz uma saída $Yi$ através do combinador linear e função $\delta$ de ativação; compara essa saída $Yi$ com a observação $i$ obtida do conjunto de dados (ponto chave do processo de treino supervisionado) e por fim essa comparação irá gerar um erro $e$.
            
            \subparagraph* {Critério de parada}
            	De acordo com algum critério adotado em cada contexto de aplicação do perceptron, este erro pode ser aceitado e o neurônio mantém o valor de seus pesos $Wi$ que impactam na saída $Yi$ desejada. A aprendizagem do neurônio também pode atingir um critério de parada após N épocas de treinamento, diversos critérios de paradas  podem ser combinados.  
            	
            \subparagraph* {Época de treinamento}
            	Se o critério de parada não for aprovado, uma nova época de treinamento (ou repetição de interação) é iniciada mesmos valores $X_i$ e $Y_i$ passados, os valores de pesos $Wi$ são reajustados com a taxa de aprendizagem, buscando o objetivo de se obter um erro menor.
            	
            \subparagraph* {Taxa de aprendizagem}
            	Esse reajuste de pesos $Wi$ denomina-se taxa de aprendizagem, $\alpha$ que pode ter valores de escolha livre ao contexto de aplicação do perceptron, para reajustar estes pesos $Wi$. Assim que a taxa de aprendizagem ajusta os pesos, uma nova época N+1 de treinamento está se iniciando buscando novamente um erro menor. Ressaltando então que o critério de parada pode ser acionado e interromper o reinicio do processo, se for estipulado um limite para o valor de N combinado ou não com um limite para o erro. 
            	
          \subsection {Funcionamento e treino do neurônio perceptron}
            Em \cite{Almeida2013} verifica-se de forma procedural, o processo do treino supervisionado do perceptron, com $m$ observações $Y$ = $(Y_{i},Y_{i+1}...,Y_{m})$ com $n$ entradas $X$ relacionadas à cada $Y_m$, ocorre da seguinte maneira: 
            Matematicamente o neurônio é representado por um vetor global de $n$ pesos sinápticos $(W_0, W_{1}, ..., W{n})$ , e um valor de bias $b$. O processo do algoritmo abaixo ajustará esses pesos e bias.
            \begin{enumerate}
              \item Coleta do valor supervisionado inicial $Y_{0}$, que é a primeira observação histórica do conjunto de dados.
              \item Coleta do vetor de variáveis $(X_{00}, X_{01}, ..., X_{0n})$ relacionados à saída supervisionada $Y_i$.
              \item Inicialização dos pesos sinápticos $(W_0, W_{1}, ..., W{n})$ com valores aleatoriamente pequenos.
              \item Definição de um valor real entre 0 e 1 para a taxa de aprendizado $\alpha$.
              \item Definição do valor inicial de bias $b$.
              \item Definição da função de ativação $\delta$ 
              \item Definição do limite de épocas de treino $l_e$, se não houver, definir $l_e$ para -1.
              \item LAÇO: Percorrer e atribuir em ($Y_d$) de $Y_0$ até $Y_m$, inicializando o contador de épocas $c_e$ = 0, enquanto $CP(e)$ for verdadeiro E/OU ($l_e$) for menor que $c_e$:
              \item Nova coleta do vetor de variáveis $(X_{d0}, X_{d1}, ..., X_{dn})$ relacionados à saída supervisionada $Y_d$.
              \item Incrementar 1 em $c_e$.
              \item Cálculo do sinal $u = \sum_{i=1}^{n}X_{di}*W_{i}+b$
              \item Aplicação de valor de $U$ na função de ativação $\delta$ obtendo $Y_u = \delta(u)$
              \item Obtenção do erro $e = Y_d-Y_u$
              \item Aplicação do critério de parada $CP$ em relação ao erro $e$; $CP(e)$
              \item SE $CP(e)$ for APROVADO, o algoritmo continua, SE REPROVADO, a aprendizagem é feita ajustando $b_{}=b_{}+(\alpha*(e))$, e ajustando o vetor $W_{i} = W_{i}+(\alpha*e*X_{di})$. 
            \end{enumerate}
 
        \paragraph* {Funcionamento do perceptron para logica AND}.\\
		 Este exemplo aborda a aplicação do problema do neurônio de Warren McCulloch e Walter Pitts, o aprendizado para a tabela AND, que busca fornecer uma resposta verdadeira apenas se a primeira E todas as demais entradas forem verdadeiras.\\            	
        A utilização do perceptron com o modelo de aprendizado supervisionado, busca então conseguir de forma autônoma os valores de pesos $W_i$ e desta forma aprender o funcionamento da logica E, sem que seja necessário a tarefa humana de ajustar o mesmo.\\
                 \begin{table}[!ht]
                 \centering
  				  \begin{tabular}{|c|c|c|c|}
  				 	\hline  \textbf{linha} & \textbf{$X_0$} & \textbf{$X_1$} &  \textbf{$Y$}\\
  				 	\hline 0 & 0 & 0 & 0\\
  				 	\hline 1 & 0 & 1 & 0\\
  				 	\hline 2 & 1 & 0 & 0\\
  				 	\hline 3 & 1 & 1 & 1\\
  				  \end{tabular}
                \end{table}
					
  Para este aprendizado vamos definir o critério de parada de 0 para o erro. 
  Definir o valor 0 para o $bias$. 
  1 para $\alpha$ e 
  função $\delta(u)$ = $degrau$ (1, se $u>=0$, 0 se $u<0$).
  O número de épocas terá o mesmo número de valores supervisionado, então o treino executará 1 vez para cada observação.
  			 	   
  			 	 linha $d$ = 0
	  			 \begin{enumerate}
	  			    
	  			 	\item Coleta do valor supervisionado $Y_d$ = $Y_0$ = 0.
	  			 	\item Coleta do vetor de variáveis $(X_{00} = 0, X{01}=0)$.
	  			 	\item Inicialização dos todos os pesos com valores aleatoriamente pequenos: $W_0=3,W_1=3$
	  			 	\item Definição da taxa de aprendizado $\alpha = 1$.
	  			 	\item Definição do valor de bias $b=3$.
	  			 	\item Definição da função de ativação $\delta = degrau$  
	  			 	\item Cálculo do sinal $u = x_{00}*w_0 + x_{01}*w_1 +b = (0*3+0*3+0) = 0$
	  			 	\item Aplicação de valor de $u$ na função de ativação $\delta$ obtendo $Y_u$, $Y_u = \delta(0) = 1$
	  			 	\item Obtenção do erro $e = Y_0-Y_u = 0 - 1 = -1$
	  			 	\item Aplicação do critério de parada $CP$ em relação ao erro $e$ REPROVADO, pois o erro esperado é 0.
	  			 	\item Como $CP$ foi reprovado, a aprendizagem é realizada $b=b+(\alpha*e)$ e $W_i=W_i + (\alpha*e)*X_{0i}$
	  			 \end{enumerate}		
  				
    				Aprendizagem:
    				\begin{enumerate}
    					\item $b=b+(\alpha*e) = 0 + 1*(-1) = -1 $  					
    					\item $W_0=W_0 + (\alpha*e)*X_{00} = 3 + 1*(-1)*0 = 3$
    					\item $W_1=W_1 + (\alpha*e)*X_{01} = 3 + 1*(-1)*0 = 3$
    				\end{enumerate}	
    				
    				Reinicio dos pesos reajustados pela aprendizagem e apresentação da próxima linha ao neurônio:
    				linha $d$ = 1.\\
    				\begin{table}[!ht]
                    \centering
    				\begin{tabular}{|c|c|c|c|}
    					\hline  \textbf{linha} & \textbf{$X_0$} & \textbf{$X_1$} &  \textbf{$Y$}\\
  				 	    \hline 1 & 0 & 1 & 0\\
    				\end{tabular}
    				\end{table}
    				
    				
    				\begin{enumerate}
    				    \item Coleta do valor supervisionado $Y_d$ = $Y_1$ = 0.
    					\item Cálculo do sinal $u = X_{10}*w_0 + X_{10}*W_1 +b = (0*3 + 1*3 -1) = 0$
    					\item Aplicação de valor de $u$ na função de ativação $\delta$ obtendo $Y_u$, $Y_u = \delta(0) = 1$
    					\item Obtenção do erro $e = Y_d-Y_u = 0 - 1 = -1$
    					\item Aplicação do critério de parada $CP$ em relação ao erro $e$ reprovado, pois o erro esperado é 0.
    					\item Como $CP$ foi reprovado, a aprendizagem é realizada $b=b+(\alpha*e)$ e $W_i=W_i + (\alpha*e)*X_{1i}$
    				\end{enumerate}
    				
    				Aprendizagem:
    				\begin{enumerate}
    					\item $b=b+(\alpha*e) = -1 + 1*(-1) = -2 $  					
    					\item $W_0=W_0 + (\alpha*e)*X_{10} = 3 + 1*(-1)*0 = 3$ 
    					\item $W_1=W_1 + (\alpha*e)*X_{11} = 3 + 1*(-1)*1 = 2$
    				\end{enumerate}
    				
    				Reinicio dos pesos reajustados pela aprendizagem e apresentação da próxima linha ao neurônio:
    				linha $d$ = 2\\
    				\begin{table}[!ht]
                    \centering
    				\begin{tabular}{|c|c|c|c|}
    					\hline  \textbf{linha} & \textbf{$X_0$} & \textbf{$X_1$} &  \textbf{$Y$}\\
  				 	    \hline 2 & 1 & 0 & 0\\
    				\end{tabular}
    				\end{table}
            	
            	
            	\begin{enumerate}
            	    \item Coleta do valor supervisionado $Y_d$ = $Y_2$ = 0.
            		\item Cálculo do sinal $u = X_{20}*w_0 + X_{20}*W_1 +b = (1*3 + 0*2 -2) = 1$
            		\item Aplicação de valor de $u$ na função de ativação $\delta$ obtendo $Y_u$, $Y_u = \delta(1) = 1$
            		\item Obtenção do erro $e = Y_d-Y_u = 0 - 1 = -1$
            		\item Aplicação do critério de parada $CP$ em relação ao erro $e$ reprovado, pois o erro esperado é 0.
    				\item Como $CP$ foi reprovado, a aprendizagem é realizada $b=b+(\alpha*e)$ e $W_i=W_i + (\alpha*e)*X_{2i}$
            	\end{enumerate}
            
            	
            	Aprendizagem:
            	\begin{enumerate}
            		\item $b=b+(\alpha*e) = -2 + 1*(-1) = -3 $  					
            		\item $W_0=W_0 + (\alpha*e)*X_{20} = 3 + 1*(-1)*1 = 2$ 
            		\item $W_1=W_1 + (\alpha*e)*X_{21}= 2 + 1*(-1)*0 = 2$
            	\end{enumerate}	
            	
            	Reinicio dos pesos reajustados pela aprendizagem e apresentação da próxima linha ao neurônio:
    				linha $d$ = 3\\
    				\begin{table}[!ht]
                    \centering
    				\begin{tabular}{|c|c|c|c|}
    					\hline  \textbf{linha} & \textbf{$X_0$} & \textbf{$X_1$} &  \textbf{$Y$}\\
  				 	    \hline 3 & 1 & 1 & 1\\
    				\end{tabular}
    				\end{table}
            	
            	\begin{enumerate}
            	    \item Coleta do valor supervisionado $Y_d$ = $Y_3$ = 1.
            		\item Cálculo do sinal $u = X_{30}*w_0 + X_{30}*W_1 +b = (1*2 + 1*2 -3) = 1$
            		\item Aplicação de valor de $u$ na função de ativação $\delta$ obtendo $Y_d$, $Y_u = \delta(1) = 1$
            		\item Obtenção do erro $e = Y_d-Y_u = 1 - 1 = 0$
            		\item Aplicação do critério de parada $CP$ em relação ao erro $e_n$ APROVADO, então conclui-se que os pesos sinápticos estão corretos.
            	\end{enumerate}
                
            	Pesos finais e bias aprovados pelo processo de treino:
            	\begin{enumerate}
            		\item $b=  -3$  					
            		\item $W_1= 2$ 
            		\item $W_2= 2$
            	\end{enumerate}	
            	
            	Fim do processo de treino.
            
            \subparagraph* {Validação do treino}
            	Após todo o processo de treino e apresentação dos conjuntos, é necessário realizar um novo ciclo no perceptron, para ver se o neurônio responde corretamente ao modelo de dados inicial.
            	
            	Pesos finais e bias aprovados pelo processo de treino:
            	\begin{enumerate}
            		\item $b=  -3$  					
            		\item $W_1= 2$ 
            		\item $W_2= 2$
            	\end{enumerate}
            	
                linha $d$ = 0\\
                    \begin{table}[!ht]
                    \centering
    				\begin{tabular}{|c|c|c|c|}
    					\hline  \textbf{linha} & \textbf{$X_0$} & \textbf{$X_1$} &  \textbf{$Y$}\\
  				 	    \hline 0 & 0 & 0 & 0\\
    				\end{tabular}
    				\end{table}
    				
            	\begin{enumerate}
            	    \item Coleta do valor supervisionado $Y_d$ = $Y_0$ = 0.
            		\item Cálculo do sinal $u = X_{00}*w_0 + X_{01}*W_1 +b = (0*2 + 0*2 -3) = -3$
            		\item Aplicação de valor de $U$ na função de ativação $\delta$ obtendo $Y_u$, $Y_u = \delta(-3) = 0$
            		\item Obtenção do erro $e = Y_i-Y_u = 0 - 0 = 0$
            		\item Aplicação do critério de parada $CP$ em relação ao erro $e$ APROVADO, então o neurônio respondeu corretamente às entradas.
            	\end{enumerate}
            	
                linha $d$ = 1\\
                    \begin{table}[!ht]
                    \centering
    				\begin{tabular}{|c|c|c|c|}
    					\hline  \textbf{linha d} & \textbf{$X_0$} & \textbf{$X_1$} &  \textbf{$Y$}\\
  				 	    \hline 1 & 0 & 1 & 0\\
    				\end{tabular}
    				\end{table}
    				
            	\begin{enumerate}
            	    \item Coleta do valor supervisionado $Y_d$ = $Y_1$ = 0.
            		\item Cálculo do sinal $u = X_{10}*w_0 + X_{11}*W_1 +b  = (0*2 + 1*2 -3) = -1$
            		\item Aplicação de valor de $u$ na função de ativação $\delta$ obtendo $Y_u$, $Y_u = \delta(-1) = 0$
            		\item Obtenção do erro $e = Y_d-Y_u = 0 - 0 = 0$
            		\item Aplicação do critério de parada $CP$ em relação ao erro $e$ APROVADO, então o neurônio respondeu corretamente às entradas.
            	\end{enumerate}
            
            	linha $d$ = 2\\
            	    \begin{table}[!ht]
                    \centering
    				\begin{tabular}{|c|c|c|c|}
    					\hline  \textbf{linha d} & \textbf{$X_0$} & \textbf{$X_1$} &  \textbf{$Y$}\\
  				 	    \hline 2 & 1 & 0 & 0\\
    				\end{tabular}
    				\end{table}
    				
            	\begin{enumerate}
            	    \item Coleta do valor supervisionado $Y_d$ = $Y_2$ = 0.
            		\item Cálculo do sinal $u = X_{20}*w_0 + X_{21}*W_1 +b  = (1*2 + 0*2 -3) = -1$
            		\item Aplicação de valor de $u$ na função de ativação $\delta$ obtendo $Y_u$, $Y_u = \delta(-1) = 0$
            		\item Obtenção do erro $e = Y_d-Y_u = 0 - 0 = 0$
            		\item Aplicação do critério de parada $CP$ em relação ao erro $e$ APROVADO, então o neurônio respondeu corretamente às entradas.
            	\end{enumerate}
            
            	linha $d$ = 3\\
            	    \begin{table}[!ht]
                    \centering
    				\begin{tabular}{|c|c|c|c|}
    					\hline  \textbf{linha d} & \textbf{$X_0$} & \textbf{$X_1$} &  \textbf{$Y$}\\
  				 	    \hline 3 & 1 & 1 & 1\\
    				\end{tabular}
    				\end{table}
    				
            	\begin{enumerate}
            	    \item Coleta do valor supervisionado $Y_d$ = $Y_3$ = 0.
            		\item Cálculo do sinal $u = X_{30}*w_0 + X_{31}*W_1 +b  = (1*2 + 1*2 -3) = 1$
            		\item Aplicação de valor de $u$ na função de ativação $\delta$ obtendo $Y_u$, $Y_u = \delta(1) = 1$
            		\item Obtenção do erro $e = Y_d-Y_u = 1 - 1 = 0$
            		\item Aplicação do critério de parada $CP$ em relação ao erro $e$ APROVADO, então o neurônio respondeu corretamente às entradas.
            	\end{enumerate}
           
           		Como o neurônio não teve nenhum critério de parada REPROVADO em todas as interações de todas as linhas, podemos dizer que o mesmo está devidamente treinado e validado para a solução do problema.
            
        \subsection{Limite de um Perceptron}
          É possível reparar que o processo de aprendizagem de um perceptron, se forma por uma combinação linear que é o valor $ u $ dos pesos e entradas xi. Essa combinação pode ser aprovada ou reprovadas no processo repetitivo de treino controlado pela função $\delta$, e pela aprovação do erro medido entre o valor da combinação linear e o valor esperado.
          
          Então em 1969, Marvin Mjinsky e Seymour Papert realizaram uma publicação comprovando essa limitação de aprendizado à uma combinação linear, e provaram que o perceptron é limitado à resolução de problemas que são resolvidos ou classificados por apenas 1 linha, ou seja, problemas linearmente separáveis que consiste na mesma limitação do processo de regressão linear múltipla.
          Na figura 10, abaixo, o perceptron não pode solucionar o problema (b). E essa limitação desmotivou e parou os estudos com perceptrons.
    		  \begin{figure}[!ht]
    		  	\center{
    		  		\includegraphics[width=0.65\textwidth]
    		  		{10-limite-perceptron.png}
    		  	}
    		  	\caption{Problemas Linearmente Separáveis e Não Separáveis. Retirado de \cite{Flavia2014}.\label{fig:problemasLineares}}
    		  \end{figure}
	  	
	  	 Em 1986 James McClelland e David Rumelhart proporam o método de desenvolvimento de uma rede neural de perceptrons, tangindo mais ainda a inspiração da solução no cérebro humano. O processo resume o treinamento do perceptron simples aplicado à um conjunto de perceptrons interligados, e assim solucionando problemas complexos que podem ser resolvidos com uma combinação de soluções.
	  	  
  	  	  \begin{figure}[!ht]
  	  	  	\center{
  	  	  		\includegraphics[width=0.30\textwidth]
  	  	  		{11-solucao-mlp.png}
  	  	  	}
  	  	  \caption{Problemas Linearmente Não Separáveis Multiplas Soluções. \label{fig:doisPerceptrons}}
  	  	   \end{figure}
  	    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   
  	    \subsection{Rede Perceptrons Múltiplas Camadas - MLP}
  	       
  	       A solução base para se combinar 2 ou mais perceptrons a fim de se resolver um problema com a combinação de 2 ou mais soluções lineares, é a utilização de um perceptron combinador de sinal de saída, já que cada perceptron pode ter múltiplas entradas e somente uma saída. Dessa forma as redes neurais vão formando colunas de perceptrons interconectados. Cada coluna é denominada uma camada da rede neural. A ultima camada deve ter o número de perceptrons correspondente ao número de saídas desejadas. Na figura abaixo, encontra-se uma rede neural com duas camadas intermediárias e 3 saídas.
  	       
  	       \begin{figure}[!ht]
  	       	\center{
  	       		\includegraphics[width=0.65\textwidth]
  	       		{12-mlp.png}
  	       	}
  	       	\caption{Rede de perceptrons com múltiplas camadas. Retirado de \cite{Almeida2013}\label{fig:MLP}}
  	       \end{figure}
         
  	       Esta rede denominada MLP (Multilayer Perceptron) possui uma camada de entrada onde cada nó representa uma variável a ser considerada ao problema a ser analisado, e pelo menos uma camada intermediária.
  	      
  	       Nesta camada intermediária os neurônios possuem geralmente uma função de ativação sigmoidal logística ou tangente hiperbólica, e conceitualmente no mínimo 1 neurônio desta primeira camada oculta deve receber no mínimo 2 conexões de entrada. E uma camada de saída, na borda à direita, com o número de neurônios correspondente ao número de soluções buscadas. 
  	       
            \paragraph{Treino e Validação da MLP}
            	O conjunto de dados de entrada na rede MLP supervisionada, deve ser dividido em 2 partes principais, Treinamento e Validação. É importante salientar que as observações de ambos os conjuntos devem originar do mesmo conjunto de dados para representar o mesmo problema, as observações $Y_i$ relacionadas aos vetores $i$ de variáveis $X_{i1},Xi_{i2},...,X{ij}$ do conjunto de treino, devem ter a mesma estrutura, mesmo número j de variáveis X por vetor de entrada e devem representar o mesmo problema que as observações $Yi$ do conjunto de validação.
            	
            	O conjunto de dados da validação e treino somados devem formar exatamente o conjunto original, sem informações excedentes ou em falta.
            	
            	Os dados de treino e dados de validação, podem ser separados de forma aleatória, sendo os dados de treino os responsáveis pelos reajustes de pesos e capacidade de generalização da rede, e os dados de validação responsáveis pelo processo de validação pós-treino.
            	
            	É importante adotar um bom critério de parada de treino, pois um treino prolongado tende a convergir em ajustes de pesos memorizados dos valores observados nos dados de treino e isso causa o fenômeno de overfitting na rede neural, que é a perda da capacidade de generalização. Pesos sinápticos que sofrem processo prolongado de reajustes acaba "viciando" a rede neural para reconhecer apenas os dados de treino.
            	
            	Parada do erro mínimo:
            	O critério de parada do erro mínimo encerra o treinamento da RNA quando a mesma obtém um erro menor que o mínimo estipulado para o valor observado, este é o critério mais simples, adotado nos casos onde existe um limiar de erro já determinado pelo problema, entre o valor observado e o valor a se predizer.
            	
            	Parada por número de épocas:
            	Um critério de parada pode ser limitado também ao número de épocas de treino. A determinação  deste número de épocas pode ocorrer por tentativa e erro, visto que haverá a convergência de um número pequeno para uma baixa capacidade de aprendizado, e a convergência de um número grande para o processo de overfitting. Logo é necessário realizar experimentos que validem número de épocas fora desses intervalos de convergência.
            	
            	Parada por validação cruzada:
            	Por fim a validação cruzada é a técnica que se utiliza os dados dos conjuntos de validação e treino de forma cruzada, neste processo então, os dados de treino são utilizados no processo interativo de aprendizagem, e no fim deste processo o conjunto é validado com os dados de validação, obtendo-se um novo erro de validação.
            	A medição do erro de validação passa por um processo de avaliação em função do número de épocas, a fim de se detectar um ponto de número de épocas onde o erro quadrático médio da amostra de validação sofre uma curva de crescimento após um limiar de decréscimo.
            	
            	É notório observar que o erro quadrático médio das amostras de treinamento sofrerá um decréscimo em função do aumento do número de épocas de treinamento, convergindo ao processo de overfitting, ou memorização da rede.
            	
            	O ponto de parada no limite inferior do erro quadrático médio da amostra de validação, será o ponto ótimo de parada de treinamento.
          	
          	\begin{figure}[!ht]
          		\center{
          			\includegraphics[width=0.65\textwidth]
          			{14-validacaocruzada.png}
          		}
          		\caption{Ponto ótimo de parada da validação cruzada. Retirado de \cite{Flavia2014} \label{fig:validacaoCruzada}}
          	\end{figure}
        
        O treinamento de uma rede MLP para previsões de demanda de restaurantes universitários que obteve sucesso em \cite{Lopes2008} e \cite{Rocha2011} é a retro propagação de erro.
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \subsection{Perceptrons Múltiplas Camadas com Retro Propagação de Erro}
        A rede Perceptron Múltiplas Camadas com Retro Propagação de Erro (do inglês, M.L.P Backpropagation), faz o reajuste dos pesos sinápticos dos neurônios através de duas fases:
  	       \paragraph{Feed-forward} Nesta primeira fase de treino os sinais $X_{i0},X_{i0},...,X_{in}$ com sua respectiva saída $Y_i$ do conjunto de dados são apresentados à todos os neurônios da primeira camada. O processo de propagação do sinal de saída de cada neurônio segue o princípio do neurônio artificial apresentado na seção anterior, que envia o sinal de saída como um sinal de entrada ao neurônio seguinte.
  	       
  	       \paragraph{Feed-backward} Nesta fase é obtido um valor de erro da camada de saída. Este erro é utilizado na equação de reajuste do peso sináptico das conexões dos neurônios da camada de saída com o sinal de saída dos neurônios da última camada oculta. E depois este erro é propagado realizando outra equação de reajuste de peso sináptico das conexões dos neurônios nas camadas anteriores, no sentido contrário em direção à camada de entrada. Isto permite que os pesos sináptico de todas as camadas de intermediárias neste processo tenham seus pesos ajustados.
  	       
  	       \begin{figure}[!ht]
  	       	\center{
  	       		\includegraphics[width=0.65\textwidth]
  	       		{13-mlp-back.png}
  	       	}
  	       	\caption{Fases de treino da MLP-Back-Propagation. Retirado de \cite{Almeida2013}\label{fig:MLP2}}
  	       \end{figure}
  	       
  	       \paragraph*{MLP Backpropagation em R.U em trabalhos relacionados}
  	       Em \cite{Lopes2008} A rede neural perceptron de múltiplas camadas é utilizada para tratar a previsão de demanda do R.U da UFV, utilizando apenas como variáveis quantitativas as 5 ultimas observações anteriores ao dia a se analisar, e como variáveis qualitativas o dia da semana variando de segunda a sexta, em valores binários.
  	       
           \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.65\textwidth]
          		{15-rna-lopes.png}
          	}
          	\caption{Rede Neural Perceptron de Múltiplas Camadas. Retirado de \cite{Lopes2008}.\label{fig:mlp-lopes}}
           \end{figure}
            
           Em \cite{Rocha2011} o trabalho realizado com neurônios artificiais para prever a demanda do R.U da UNESP, envolve apenas uma única camada de entrada e uma segunda camada para saída, porém com uma diversidade maior de variáveis de entrada correlacionadas com o consumo do restaurante. 
           \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.65\textwidth]
          		{16-rna-rocha.png}
          	}
          	\caption{Rede Neural Perceptron de Múltiplas Camadas. Retirado de  \cite{Rocha2011} \label{fig:rnaRocha}}
           \end{figure}
         
            Ambos os modelos possuem topologia de uma camada oculta para entrada dos dados, e uma camada de saída. que de acordo com \cite{Braga2000} cita que através de uma análise de Cybenko, uma camada intermediária é o suficiente para aproximar qualquer função contínua e 2 camadas intermediárias são suficientes para aproximar qualquer função matemática, e devendo ser observado o fato de que em alguns casos, a utilização de 2 ou mais camadas pode facilitar o treinamento da rede, porém a utilização de um grande número de camadas intermediárias ou ocultas, é inviável, pois em cada uma delas a estimativa do erro se trata de uma estimativa da estimativa do erro da camada anterior, e este cascateamento de estimativas pode se tornar menos preciso à medida que cresce.
            
            \cite{Flavia2014} cita que o número de neurônios na primeira camada oculta é proporcional à dimensão do espaço de observação. Logo em modelos preditivos de demanda, supracitados, observa-se que no mínimo, na primeira camada oculta, é utilizado um número de neurônios igual ao número de variáveis que influenciam no dado preditivo.
            
            \paragraph*{Parâmetros de treino da MLP Backpropagation}
            A definição da função $\delta$ de ativação interfere na linearidade  do modelo a ser analisado, sendo a função sigmoide a mais popular na literatura. 
            
            A taxa de aprendizagem, define a velocidade de reajuste dos pesos, podendo variar de 0 a 1. Ressalta-se que uma taxa próxima de 1 provoca picos oscilatórios na taxa de aprendizado, e taxa próxima de 0 provoca lentidão da convergência de aprendizagem. Valores comuns de utilização ficam entre 0,2 e 0,8.
        
        \subsection{Treino da MLP - BackPropagation para 1 sinal de saída}
            No caso do problema de predição de demanda onde se busca apenas um valor de saída, que é a previsão de vendas em relação às variáveis de entrada, o cálculo de reajuste dos pesos da camada de saída é reduzido à apenas 1 neurônio na camada de saída, porém o somatório no calculo do erro pode envolver mais neurônios de saída em outros aplicações.
            
            Um vetor $i$ do conjunto de dados, de tamanho $n$ de variáveis de entrada\\ $Xi_{0}(j),Xi_{1}(j),...,Xi_{n}(j)$, que são os sinais de entrada, são apresentados à rede, relacionados à um valor supervisionado $Y_i$.
            
            Em resumo o treino da rede perceptron com backpropagation obtém o sinal de saída no último neurônio $s$ da rede, através da propagação dos sinais de saída dos neurônios anteriores da rede, feito pela aplicação da combinação linear dos sinais de entrada com os pesos sinápticos em uma função de ativação. É calculado o erro quadrático $e$ deste sinal de saída em $s$ com o valor $Yi$, e a regra do Gradiente Descendente com base neste erro é utilizada para o reajuste dos pesos sinápticos em todas as conexões de todos os neurônios. O processo é denominado regra delta generalizada, $\Delta$
            
            Neste capítulo, será denominado a função de ativação do neurônio por $F(.)$ para uma melhor coerência, devido ao símbolo $\delta$ utilizado para esta função nas seção anterior sobre o neurônio artificial ser amplamente utilizado para outros fins na regra de reajuste dos pesos sinápticos da rede MLP. Esta função na MLP - Backpropagation deve ser uma função não-linear diferenciável em todos os pontos, popularmente é usada a função sigmoide.
            
            O erro quadrático do treino de uma rede MLP com Backpropagation, com 1 sinal de saída, no neurônio de saída $s$, em uma i-ésima iteração de treino em uma determinada época $k$ será:\\ 
            $ e(i) =\frac{1}{2}*( (Yi-Yi_{\mu}(s))^2 ) $\\ onde $Y_{\mu}(s)$ é o sinal de saída deste neurônio de saída, e $Y_i$ é o valor de saída da observação do conjunto de dados.
            
            O principal objetivo de todo o método backpropagation conforme o avanço de épocas, é o treino em uma determinada época reduzir a média de erros quadráticos do conjunto de validação ( $m.s.e$ ) em $n$ iterações de validação desta época:\\
            $m.s.e = \frac{1}{n} \sum_{k=1}^{n}e(k)$
            É importante observar que 1 época consiste no par treino e validação. Logo após o treino, os erros $e(k)$ serão obtidos novamente através das entradas $Y_i$ do conjunto de validação, e respostas propagadas $Y_\mu$ na camada de saída da rede já treinada, para então o $m.s.e$ ser calculado.
            
            O valor $m.s.e$ será o critério de parada do treinamento de toda a rede e deve ser observado a cada época de treinamento, assim que este valor atingir um ponto ótimo, conforme figura deste ponto ótimo exibida anteriormente, o critério de parada será verdadeiro e o treinamento deve parar, pois a partir desse ponto a rede converge à um overfitting (divergindo de uma capacidade de generalização, e memorizando os dados de treino, podendo ter sua estimativa eficiente somente no conjunto de dados de treino).
            
            Ressaltando que toda saída de todo neurônio $j$ da rede, com $n$ entradas, é calculada através da equação:\\
            $ Y_{\mu}(j) = F(\mu)$\\
            Onde $\mu = (\sum_{i=1}^{n} (Xi_{n}(j)*Wi_{n}(j) + b)$ é o potencial de ativação do neurônio $j$ e $F$ é a função de ativação do neurônio.
            
           %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
           \paragraph*{Fase Feedforward}
            Nesta fase, em determinada época $(k)$, em um vetor de $n$ variáveis $Xi$ correspondentes à um total de venda $Yi$, todos os neurônios $j$ propagam o sinal de saída através do calculo de $Yi_{\mu}(j) = F(\mu(j))$. No cálculo de $\mu$ os pesos sinápticos de cada neurônio $j$ conectado à uma entrada $Xi_{n}(j)$ são $Wi_{n}(j)$. A saída estimada pela rede será $Yi_{\mu}(s)$.
            
            Se a iteração $i$ da época $k$ for a primeira, todos os pesos $Wi_{n}j$ em todos os neurônios, são inicializados com valores aleatórios pequenos.\\ 
            
            
            \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.65\textwidth]
          		{18-mlp-bp-ff1.png}
          	}
          	\caption{Apresentação da i-ésima observação do conjunto de treino à rede}
           \end{figure}
           
           \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.65\textwidth]
          		{18-mlp-bp-ff2.png}
          	}
          	\caption{Cálculo do valor estimado de saída da rede.}
           \end{figure}
            
            O valor de $Yi_{\mu}(j)$. dos neurônios da primeira camada oculta, são obtidos de forma que $Xi_{n}(j)$ são os sinais de entrada das variáveis de 1 à $n$.
            
            O valor de $Yi_{\mu}(j)$. dos neurônios das próximas camadas, inclusive a de saída, utiliza o sinal de saída $Yi_{\mu}$ dos neurônios da camada anterior conectados à $j$ como um sinal de entrada $Xi_{n}$.
            
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \paragraph*{Fase Feedbackward}
            O Processo de reajuste dos pesos sinápticos com o objetivo de atingir a minimalização do erro quadrático da validação, é feito pelo método do Gradiente Descendente, reajustando os pesos sinápticos $Wi_{n}(j)$ correspondente à cada neurônio $j$ da rede, para um valor $\Delta Wi_{n}(j)$, da seguinte forma:\\
            $\Delta Wi_{n}(j) = \eta*\delta_j*Xi_{n}(j)$\\
            
            \subparagraph*{Regra $\delta$ para neurônio de saída}
            Exclusivamente para a camada de saída, $\delta$ é calculado por\\
            $\delta_s = (Yi - Yi_{\mu}(s) )*F'(\mu(s))$.
            \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.40\textwidth]
          		{17-mlp-bp-saida.png}
          	}
          	\caption{Aprendizado de um neurônio na camada de saída}
           \end{figure}
            
            O valor dos $n$ pesos $Wi_{n}(s)$ do neurônio de saída $s$ com $n$ entradas vindas das saídas de neurônios $j$ das camadas anteriores, é obtido por $\Delta Wi_{n}(s) = \eta*\delta_s*Yi_{\mu}(j)$\\.
            \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.65\textwidth]
          		{20-mlp-bp-fb.png}
          	}
          	\caption{Reajuste dos pesos de saída}
           \end{figure}
           %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
           \subparagraph*{Regra $\delta$ para neurônios de camadas ocultas}
            Nesta etapa, os neurônios $n$ da camada oculta obterão seu $\delta$ através da seguinte equação usando o $\delta$ dos $m$ neurônios da camada posterior que se conectam à ele:\\ 
            
            $\delta_n = F'(\mu(n))*(\sum \delta_m*Wi_{n}m)$\\
            
            Na rede neural de 1 camada oculta e 1 neurônio de saída, a soma será reduzida à apenas 1 neurônio, ficando então a regra $\delta$ da seguinte forma:\\
            
            $\delta_n = F'(\mu(n))*(\delta_s*Wi_{n}s)$\\
            
            Por fim os pesos das $n$ entradas $Wi_{n}(n)$ conectadas ao neurônio $n$ terão seus pesos reajustados para a próxima iteração da seguinte forma:\\
            $\Delta W(i+1)_{n}(n) = \eta*\delta_n*Xi_{n}(n)$\\
            
            Após o reajuste chegar na primeira camada oculta, um novo vetor de observações $i$ é apresentado à rede repetindo, iniciando novamente a fase feed-forward e repetindo o ciclo até o fim das entradas.
            
            \begin{figure}[!ht]
          	\center{
          		\includegraphics[width=0.65\textwidth]
          		{21-mlp-bp-fbe.png}
          	}
          	\caption{Reajuste dos pesos de camadas ocultas}
            \end{figure}
           
            \subparagraph{Validação de treino}
            Após se encerrar uma época, que percorreu todas as i-ésimas entradas do conjunto de treino, um conjunto de dados de validação, previamente separado, é apresentado à rede.
            A validação ocorre só com a fase feedforward, obtendo-se os erros quadráticos da camada de saída com o dado de validação observado.
            Então é calculado o $m.s.e$, obtendo-se a média de todos os i-ésimos erros quadráticos do conjunto de validação.
            O valor $m.s.e$ deve ser acompanhado até que se atinja um ponto ótimo, ou seja, um limite inferior após k épocas.
            Quando este limite for atingido em uma época $k_o$, todos os parâmetros da rede dentro da época $k_o$ serão os parâmetros desejados do modelo final da rede.
            
            Quando a curva do $m.s.e$ estiver sendo realizada, não se saberá o ponto ótimo de parada, até que ele comece a ser superado, logo é importante arbitrar um número $l$ para salvar os parâmetros das $l$ épocas anteriores.
        
        \subsection{Algoritmo de treino e validação backpropagation}
            Parâmetros de entrada:
            \begin{itemize}
                \item 'rna'[][], Grafo de nós do tipo neurônio, da rede neural, onde rna[m][n] corresponde ao nó "n" da camada "m".
                \item valor real $\eta$, Taxa de aprendizado .
                \item Yt[][] e Yv[][], Matrizes de valores reais Yt do conjunto de treino e Yv do conjunto de validação, onde Y[0][0] corresponde ao primeiro valor supervisionado, e Y[0][m] corresponde ao último parâmetro X relacionado ao valor supervisionado.
                \item L, Limite do contador de épocas, a cada novo erro mínimo o contador $m.s.e$ é zerado, após o limite L do aumento de erros do $m.s.e$ o treino é interrompido.                
            \end{itemize}

            O principal critério de parada do treino, será o contador L.
            Durante o treino os valores de $m.s.e$ sofrerão uma curva com similaridade parabólica, concavidade apontada para cima, conforme Figura 12 da seção 2.3.5. Busca-se então obter o valor mínimo desta curva.
            O treino trabalhará com 2 cópias do grafo rna[][]. Sendo rnaAtual[][] atual, e rnaMinimo[][].
			A cada novo valor mínimo encontrado, o rnaMinimo[][] receberá o rnaAtual[][], ao fim do treino quando o limite L de incremento de erros for superado, o treino será interrompido retornado o grafo rnaMinimo[][]

            \begin{enumerate}
                \item Instancie rnaAtual[][] e rnaMinimo[][].
                \item Instancie um contador inteiro de erros ce=0.
                \item Copie rna[][] para rnaAtual[][] e rnaMinimo[][].
                \item Inicialize uma variável inteira, contador de épocas, ck = 0.
                \item Inicialize uma variável real, errok.
                \item Insira uma cópia de rna[][] para rnaAtual[][]
                
                \item LAÇO: conte i1, Enquanto ce<L faça:
                \item --LAÇO: conte i2, Percorra it[] em Yt[i2].
                \item ----Se i2=0, inicialize os pesos de K[atual] com valores aleatoriamente pequenos. 
                \item ----Execute a fase feedforward apresentando it[] em rnaAtual[][] e guarde o erro em errok.
                \item ----Execute a fase feedbackward reajustando os pesos de rnaAtual[][] com errok.

                \item --Inicialize um vetor temporario ev[] de tamanho Yv[].tamanho, a quantidade de observações de treino.

                \item --LAÇO: Conte i3, Percorra iv[] em Yv[i3].
                \item ----Execute a fase feedforward apresentando iv[] em rnaAtual[][] e insira o erro quadrático em ev[i].

                \item --Obtenha a média dos valores quadráticos do vetor ev[] e insira em mse[i1]
                \item --Destrua ev[].
                \item --Se mse[i1] < mse[i1 -1], rnaMinimo[][] recebe rnaAtual[][], ce = 0.
                \item --incremente ck, ck=ck+1.
                \item Retorne rnaMinimo[][]
            \end{enumerate}

  % ----------------------------------------------------------
  % Trabalhos relacionados
  % ----------------------------------------------------------
  \chapter{Trabalhos relacionados}
    \subsection{Previsão de demanda em restaurantes universitários}
        \paragraph*{} No estudo estatístico feito por \cite{Landim2016}, foi analisada a correlação entre a temperatura e o consumo de refeições nos dias de vendas do restaurante universitário do campus ICT da Unifesp, sendo que os dados continham apenas uma pequena amostra das vendas do segundo semestre de 2016. Devido ao baixo volume de ocorrências, os dados foram submetidos à reamostragem via bootstrap. De acordo com os gráficos das amostras, identificou-se que a correlação mostrada nos gráficos da primeira metade do semestre e do período total do semestre formaram distribuições bimodais. Porém, na segunda metade do semestre formou-se uma distribuição unimodal. Portanto, concluiu-se que outras variáveis e outros modelos de análises deveriam ser utilizados para esta previsão de demanda.
        
        \paragraph*{} \cite{Lopes2008} faz o mesmo estudo deste cenário do ICT UNIFESP aplicado na Universidade Federal de Viçosa (UFV). Neste estudo, os dados utilizados foram somente o histórico de vendas do restaurante universitário, e nenhuma variável de ambiente foi coletada como temperatura, precipitação, número de alunos matriculados, etc. O algoritmo utilizado foi o Traincgp (Conjugate gradient backpropagation with Polak-Ribiere updates) no software Matlab. Este algoritmo não envolve o cálculo das derivadas segundas das variáveis e converge ao mínimo da função quadrática em um número finito de iterações como cita o autor. Foram então considerados para cada nó da rede neural, o dia da semana (como segunda, terça, quarta, quinta e sexta) e cada camada dessa rede utilizando os 5 dias anteriores para cada nó (as 5 segundas anteriores, 5 terças anteriores e assim sucessivamente) e, por fim, obtido um modelo pela rede que apresentou erro máximo de 3.
        
        \paragraph*{} \cite{Rocha2011} também realiza o estudo de demanda no restaurante universitário da Universidade Estadual Paulista Júlio de Mesquita Filho (UNESP), novamente com os métodos de redes neurais artificiais com backpropagation, e utilizando apenas como fonte de dados o histórico numérico das vendas realizadas, e outras variáveis intermediárias obtidas a partir deste como médias de subconjunto de observações (médias de segundas-feiras), e a única variável de ambiente coletada foi o número de feriados próximos à observação de venda. No estudo do total de dias analisados, verifica-se que em 73\% (187 dias), o método de média simples propiciou um maior erro em relação à RNA, que por sua vez ocasionou um erro maior nos 23\% (69 dias) restantes.Em se tratando de menor desperdício, observa-se que a RNA apresenta erros maiores que 50 refeições em 13 dias, enquanto o método da média simples apresenta erros maiores que 50 refeições em 58 dias, concluindo-se então que o método de RNA foi bem mais eficiente do que o cálculo de média simples utilizado pela administração do restaurante universitário.
      
      \subsection{Previsão de demanda em outros ambientes} 
        \paragraph*{} \cite{RUAS2012} fazem uma análise de previsão de demanda de energia elétrica no estado do paraná, entre os anos de 2004 e 2006, utilizando redes neurais artificiais e máquinas de vetores de suporte. Apesar de não ser o mesmo exemplo do cenário do restaurante universitário do ICT UNIFESP, temos a distribuição dos dados de consumo coletados como uma série temporal. Nesta pesquisa de previsão de demanda de energia elétrica foi utilizada uma rede parcialmente recorrente de Elman, que permite a previsão de um passo de tempo à frente. Para que seja possível realizar a previsão para vários pontos à frente, é necessário utilizar os valores já previstos, ou seja, a saída da rede, como entradas da mesma.
        
        \paragraph*{} \cite{Almeida2013} analisa um cenário semelhante de demanda de energia elétrica, porém utilizando-se técnicas de previsão de demanda com Rede Neural Artificial do tipo Multilayer Perceptron combinado com lógica fuzzy que permite colocar variáveis de temperatura (entre outras) em um conjunto de regras que impactam no problema.
        
        \paragraph*{} \cite{Silva2010} também aplica técnicas de redes neurais para previsão de demanda de energia elétrica, com o estudo de variáveis climáticas, porém através de um modelo de MAPA SOM - (Self-Organizing Map) que é um tipo de rede neural desenvolvido para reconhecimento de padrões. Apesar de ser um modelo não supervisionado, o modelo é ideal para organizar as principais variáveis impactantes e descartáveis na previsão. O mapa som utilizado pelo autor apresenta os dados associados aos seus neurônios de forma que padrões similares encontram-se em neurônios contíguos, tendo uma organização topológica. Deste modo é possível se extrair relações abstratas entre as variáveis do vetor de dados através da sua posição nos mapas componentes, que por meio de uma escala de cores mostram a quantidade de uma variável específica em cada neurônio do mapa.
       
       \subsection{Revisão bibliográfica de diversos métodos de previsão de demanda}
        \paragraph*{} \cite{Junior2007} realiza um trabalho de comparação entre diversos métodos estocásticos e  Redes Neurais Artificiais (RNA) para a previsão da demanda de produtos cosméticos distribuídos em séries temporais. Entre as Redes Neurais, encontramos redes do tipo feedforward com o algoritmo de treino por backpropagation que foi o principal foco no trabalho de previsão do R.U na Universidade Federal de Viçosa e na Universidade Estadual Paulista Júlio de Mesquita Filho.
  % ----------------------------------------------------------
  % \chapter{METODOLOGIA}
  % ----------------------------------------------------------
  \chapter{Metodologia}
	\section{Pré-processamento}
	    \subsection{Coleta de dados endógenos.}
        	Os dados históricos de consumo no restaurante foram retirados do atual sistema banco de dados de refeições subsidiadas do Hospital São Paulo, que gerencia os dados dos refeitórios de todos as unidades da Unifesp. É importante ressaltar que tais dados são apenas de funcionários, docentes e discentes da instituição. Eventuais compras de refeições realizadas por visitantes que não possuem vínculo com a instituição não são registradas pelo sistema. 
        	
        	Apenas alguns funcionários autorizados tem acesso ao banco de dados do sistema de refeições da instituição, entre eles o fiscal de contrato do restaurante universitário. Para obter tais dados neste trabalho, foi necessário obter uma autorização com a direção do campus ICT - UNIFESP e em seguida solicitar a exportação dos dados ao fiscal. Os parâmetros dos quais o mesmo consegue realizar a exportação de dados são diversos, porém foi solicitado o formato de valores separados por vírgula que compreendem o ano de 2017 a 2018.
    
        	O modelo exportado segue o seguinte da seguinte forma abaixo, contendo o exemplo de 2 datas: \\
        	\begin{algorithm}[H]
        		"
        		CONSULTA POR PERÍODO                    ",,,,,,,,,,
        		"
        		CAMPUS: SÃO JOSÉ DOS CAMPOS                    ",,,"
        		RU: TODOS                    ",,,"
        		VINCULO: ALUNO                    ",,"
        		PERÍODO DE: 01/01/2017 A 31/10/2018                        ",,
        		DATA,VENDAS CAFÉ,VENDAS ALMOÇO,VENDAS JANTAR,VENDAS REFEIÇÃO*,TOTAL VENDAS,ENTR. CAFÉ,ENTR. ALMOÇO,ENTR. JANTAR,TOTAL ENTR. REFEIÇÃO*,TOTAL ENTRADA
        		(31/10/2018),0,395,0,395,395,0,362,0,362,362
        		(30/10/2018),0,667,0,667,667,0,437,256,693,693
        	\end{algorithm}
        
        \subsection{Dados Climáticos}
        	Também serão analisadas variáveis climáticas juntos com os dados de consumo, de forma a analisar a influência de fatores externos como temperatura média ambiente e precipitação. Tais dados podem ser obtidos de forma gratuita pelo BDMEP - Banco de Dados Meteorológicos para Ensino e Pesquisa, pertencente à instituição pública INMET - Instituto Nacional de Meteorologia, pertencente ao MINISTÉRIO DA AGRICULTURA, PECUÁRIA E ABASTECIMENTO do Governo Brasileiro. 
        	
        	É necessário um cadastro no site http://www.inmet.gov.br/portal/index.php?r=bdmep/bdmep para a obtenção dos dados. 
        	
        	A instituição contêm dados registrados de forma digital desde 1961 no país inteiro, os dados históricos referentes a períodos anteriores a 1961 ainda não estão em forma digital e, portanto, estão indisponíveis no BDMEP.
        	
        	O BDMEP pode fornecer os registros de Precipitação(mm), Temp Máxima(ºC), Temp Mínima(ºC), Insolação(horas)
        	Evaporação do Piche(mm), Temperatura Compensada Média(ºC), Umidade Relativa Média(\%), Velocidade Vento Média(mps).
        	
        	Importante ressaltar que o BDMEP leva 90 dias para registrar cada nova data.
        	
        	Serão analisadas a temperatura máxima do dia que tem registro em momento próximo à frequência de refeições no horário de almoço, umidade, pressão atmosférica e velocidade do vento em metros por segundo.
        	
        	\subsection{Enriquecimento dos Dados}
            	A informação de data, irá gerar informações derivadas da data tais como: 
            	Semestre 1 ou 2 em formato categórico e binário.
            	Dia da semana em formato categórico e binário.
            	Distancia em dias até o registro anterior e posterior.
            	
            	 
            	O dia da semana seguirá o modelo binário de acordo com os trabalho de previsão de demanda em R.U realizados por \cite{Lopes2008} e \cite{Rocha2011}.
        
        \begin{figure}[!ht]
        	\center{
        		\includegraphics[width=0.40\textwidth]
        		{04-lopes-entradas-dia-semana.png}
        	}
        	\caption{Entradas de dia da semana em cofatores. Retirado de \cite{Lopes2008}.\label{fig:entradasSemanais}}
        \end{figure}
	
	\subsection{Temporização dos dados endógenos}
        Os dados endógenos obtidos de forma discreta no conjunto de dados fornecidos pela Unifesp devem passar pelo processo de temporização em um intervalo de 5 dias, em cada registro de venda deverão ser acrescentados 5 novos atributos contendo os dados de consumo dos 5 dias anteriores. Este processo adapta o conjunto de dados para um processo de memorização das entradas que será o formato compatível de leitura nos modelos de redes neurais a serem desenvolvidos.
        \begin{figure}[!ht]
    		\center{
    			\includegraphics[width=0.80\textwidth]
    			{./Figuras/entr_almoco_offset.png}
    		}
    		\caption{Registros de consumo de refeições com intervalo temporal de 5 dias.\label{fig:entr_almoco_offset}}
	    \end{figure}
        Estrutura final do conjunto de dados indexados por data: \newline
        id	variavel					tipo \newline 
        0	SEMESTRE\_1					int64 \newline 
        1	SEMESTRE\_2					int64 \newline 
        2	SEGUNDA						int64 \newline 
        3	TERCA						int64 \newline 
        4	QUARTA						int64 \newline 
        5	QUINTA						int64 \newline 
        6	SEXTA						int64 \newline 
        7	DISTANCIA\_DIA\_ANTERIOR		int64 \newline 
        8	DISTANCIA\_DIA\_POSTERIOR		int64 \newline 
        9	PERC\_CONCLUSAO\_SEM			float64 \newline 
        10	PERC\_CONCLUSAO\_MES			float64 \newline 
        11	PRESSAO\_ATMOSFERICA			float64 \newline 
        12	TEMPERATURA					float64 \newline 
        13	UMIDADE						int64 \newline 
        14	VENTO						float64 \newline 
        15	VENDAS\_ALMOCO				int64 \newline 
        16	VENDAS\_ALMOCO\_1				int64 \newline 
        17	VENDAS\_ALMOCO\_2				int64 \newline 
        18	VENDAS\_ALMOCO\_3				int64 \newline 
        19	VENDAS\_ALMOCO\_4				int64 \newline 
        20	VENDAS\_ALMOCO\_5				int64 \newline 
        21	ENTR\_ALMOCO					int64 \newline 
        22	ENTR\_ALMOCO\_1				int64 \newline 
        23	ENTR\_ALMOCO\_2				int64 \newline 
        24	ENTR\_ALMOCO\_3				int64 \newline 
        25	ENTR\_ALMOCO\_4				int64 \newline 
        26	ENTR\_ALMOCO\_5				int64 \newline 
        27	ENTR\_JANTAR					int64 \newline 
        28	ENTR\_JANTAR\_1				int64 \newline 
        29	ENTR\_JANTAR\_2				int64 \newline 
        30	ENTR\_JANTAR\_3				int64 \newline 
        31	ENTR\_JANTAR\_4				int64 \newline 
        32	ENTR\_JANTAR\_5				int64 \newline
        %TODO: INCLUIR TABELA COM O DATAFRAME COMPLETO: (./Tabelas/Todos.csv)
        % PERDI HORAS NESSA DISGRAÇA DE IMPORTAÇÃO DE TABELA.... DESISTO
        % \begin{table}[h!]
        %     \caption{FEATURES DO CONJUNTO DE DADOS}
        %     \label{dataset_amostra}
        %     \pgfplotstabletypeset[col sep=comma,
        %         columns={id,variavel},
        %         ]{./Tabelas/dataset_amostra.csv}
        % \end{table}
        
        % \begin{table}[h!]
        %     %\begin{center}
        %     \caption{FEATURES DO CONJUNTO DE DADOS}
        %     \label{dataset_amostra}
        %     \pgfplotstabletypeset[
        %       multicolumn names, % allows to have multicolumn names
        %       col sep = comma, % the seperator in our .csv file
        %       display columns/0/.style={
        %     	column name=$id$, % name of first column
        %     	column type={S},string type},  % use siunitx for formatting
        %       display columns/1/.style={
        %     	column name=$variavel$,
        %     	column type={S},string type},
        %     ]{./Tabelas/dataset_amostra.csv}% filename/path to file
        %     %\end{center}
        % \end{table}
	
    	\subsection{Divisão dos Conjuntos}
            O processo experimental será realizado em 2 roteiros distintos de divisão do conjunto de dados, e os resultados obtidos entre os 2 roteiros serão comparados.
            O conjunto de dados contemplando o período de 2017 a 2019, será dividido em conjunto de treino, validação e teste da seguinte maneira: 
            - 1º Roteiro com validação e teste de semestres iguais: 
            Neste roteiro o semestre de validação será o primeiro semestre de 2018 e o conjunto de teste será no primeiro semestre de 2019, os dados de 2017, e 2018 – 2º semestre serão usados para treino. Os resultados obtidos nesta divisão irão validar a hipótese de que os modelos aprenderão especificamente a sazonalidade de consumo no primeiro semestre, se saindo melhor nos testes no primeiro semestre em comparação aos outros modelos treinados com validação no ano todo.
            \begin{itemize}
                    \item 2º Roteiro com treino, validação e teste de anos completos.
                    \item 2º Roteiro com treino, validação e teste de anos completos.
                    \item Validação com o ano de 2018
                    \item Teste com o ano de 2019             
            \end{itemize}
    
            \subsection{Tratamento das Features}
             	Nas features endógenas (dados de venda e consumo):
             	\begin{itemize}
                    \item	Normalizar os dados de venda e consumo para o máximo e mínimo de 3x o desvio padrão. 
                    \item	Escalar os dados entre 0 e 1
                \end{itemize}
                Nas features exógenas:
                \begin{itemize}
                    
                    \item	Escalar os dados entre 0 e 1
                    \item	As features categóricas binárias (dias da semana e semestre) já estarão escaladas
                    \item   Plotar gráficos de comportamento da feature com correlação do comportamento de consumo de refeições.
                \end{itemize}
    \section{Definição e treino dos modelos}
        \subsection{Avaliação de modelos modernos}
         	De acordo com \cite{DLB} no capítulo de arquitetura de redes neurais gated recurrent unit gru, as redes recorrentes GRU são uma melhoria das redes recorrentes padrão clássicas encontradas na literatura, pois utilizam elementos que decidem o valores de saída das unidades, e que podem memorizar informações de entrada dadas por um grande intervalo de tempo, sem sofrer dissipação destes valores, com o aproveitamento de recursos de memória computacionais. Logo serão indicadas na aplicação deste trabalho para a memorização da sazonalidade semestral e anual dos dados do restaurante universitário.
         	%TODO-T: figura 23 estorando a  margem no titulo
            \begin{figure}[!ht]
            	\center{
            		\includegraphics[width=0.80\textwidth]
            		{./Figuras/gru_arch.jpg}
            	}
            	\caption{Arquitetura do modelo GRU, extraído de http://deeplearningbook.com.br/arquitetura-de-redes-neurais-gated-recurrent-unit-gru/ \label{fig:gru-arch}}
            \end{figure}
        \subsection{Topologia}
            \paragraph{Sobre a necessidade de se implementar modelos mistos}
                No conjunto de dados deste trabalho, os dados obtidos se dividem em dados temporais (onde cada registro de consumo e venda trás a informação de seu domínio em um intervalo de 5 dias anteriores) e dados discretos onde temos variáveis categóricas de data para cada registro, e variáveis climáticas, porém sem a aplicação de um intervalo temporal, ou seja, os dados exógenos são discretos, e os endógenos contínuos.
                Portanto é necessária a implementação de modelos específicos para entradas temporais e discretas.
                Para a saída final pode ser implementado um comitê de redes neurais endógenas e exógenas, com um neurônio perceptron na saída, recebendo os 2 valores dos modelos endógenos e exógenos e regredindo ao valor de saída que será a predição do consumo.
         	\subsubsection{Modelos endógenos}
         	\begin{itemize}
             	\item   Adaptar o conjunto de entrada para entradas compatíveis do modelo de rede neural GRU e do modelo fundamentado em \cite{Lopes2008} conforme a figura \ref{fig:mlp-lopes} da rede neural para leitura dos valores temporais, onde cada linha de entrada trará os dados de consumo das 5 linhas anteriores.
                \item	Desenvolver as redes perceptron de baixa profundidade para avaliar o aprendizado da rede
                \item	Aumentar a profundidade da rede e avaliar as mudanças da função de perda rmse
                \item	Implementar e avaliar modelos com redes recorrentes GRU, conforme a figura \ref{fig:gru-arch} que são especialmente desenvolvidos para o aprendizado com memorização de dados, e no caso deste trabalho, poderão memorizar as sazonalidades semanais de consumo (de até 5 dias, dado a temporização do conjunto em 5 dias).
            \end{itemize}
            \subsubsection{Modelos Mistos : Endógenos e Exógenos}
                \begin{itemize}
                    \item Para os dados temporais (consumo e venda) utilizar os melhores modelos endógenos dos experimentos anteriores para as entradas endógenas. 
                    \item Para os dados discretos e categóricos adaptar a entrada destes dados para rede perceptron
                    \item  Concatenar a saída das 2 redes neurais em um neurônio percetron criando um comitê de redes neurais para obter a saída final prevista.
                \end{itemize}
                %TODO-T: FIGURA 24 ESTORANDO MARGEM DO TITULO
	\subsection{Função de ativação}
	    \begin{figure}[!ht]
        	\center{
        		\includegraphics[width=0.80\textwidth] {./Figuras/mc_ai/activation_functions.png}
        	}
        	\caption{Funções de Ativação, imagem extraída de : \cite{MCAI} https://mc.ai/complete-guide-of-activation-functions/ \label{fig:activation_functions}}
        \end{figure}
	    \subsubsection{Para a entrada e camadas ocultas}
    	    A função ReLu será simples e eficiente para a aplicação nos experimentos, visto que na fase feed-forward terá efeito parecido com a função identidade, e na fase feed-backward durante o reajuste dos pesos pelo otimizador, irá produzir efeito degrau zerando valores negativos sendo adequada na aplicação do domínio de entrada deste trabalho, visto que todas as variáveis endógenas e exógenas não possuem valores negativos.
    	\subsubsection{Para a saída}
    	    Para os valores previstos a função escolhida será a linear, pois na fase feed-backward do reajuste dos pesos pelo algoritmo de treino backpropagation, a derivada da função linear será zero, portanto os valores e peso de saída não sofrerão reajustes, mantendo a execução do algoritmo de treino apenas nos valores de entrada e nas camadas ocultas das redes.
%TODO-T: FIGURA 25 ESTORANDO MARGEM NO TITULO    	
    \subsection{Otimizador}
        \begin{figure}[!ht]
        	\center{
        		\includegraphics[width=0.80\textwidth]
        		{./Figuras/MLM/optimizers.png}
        	}
        	\caption{Comparison of Adam to Other Optimization Algorithms Training a Multilayer Perceptron, imagem extraída de : \cite{MLM} https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/ \label{fig:otimizadores}}
        \end{figure}
        Para este trabalho será escolhido o otimizador ADAM no treino de backpropagation.
        A vantagem deste otimizador é a fusão das melhores características de 2 otimizadores :\newline 
         Momenum e RMSProp. \newline
        O Momentum acelera o reajuste dos pesos em busca dos erros globais mínimos.\newline
         O RMSProp impede a busca na direção das oscilações.\newline
         Adam ou Adaptive Moment otimization combina estas 2 heurísticas.
        O coeficiente de aprendizado escolhido para o otimizador, ou conhecido como "learning rate", será definido para a constante alpha, com valor 0.001.
        Esta constante tem produzido resultados positivos em problemas de forecast (predições) de acordo com \cite{MLM}

    \section{Teste e Métricas}
       As principal métrica de avaliação dos modelos, é a Raiz do Erro Quadrático Médio, obtido pela chamada de função "mean\_squared\_error"\ do framework Tensorflow.Keras utilizado para a modelagem,treino e predição dos modelos de redes neurais. Citado como "Loss Function" nos diversos frameworks de machine learning como TensorFlow, Matlab, Weeka entre outros) do treino dos modelos.\newline
       
        O coeficiente de correlação de Pearson, obtido pela biblioteca scipy na chamada de função \"scipy.stats.pearsonr(true,pred)"\ e o coeficiente "chi-quadrado" definido como $R^2$ obtido na chamada de função \"scipy.stats.linregress"\ será utilizado nas etapas de teste para avaliar a proximidade das predições do modelo com o comportamento real de consumo (Se acompanha as quedas e subidas de consumo ao longo do tempo).\newline
       
        Serão documentados, para trabalhos futuros, outras métricas estatísticas obtidas por esta chamada de função como os valores de slope, intercept, p\_value, std\_err.\newline
       
        A chamada de função sns.regplot(x=arr\_true,y=arr\_pred,data=df) da biblioteca seaborn irá retornar um gráfico scatter dos valores preditos e reais para a avaliação dos erros, médias e tendencia de previsão.\newline 
       
       Serão avaliados também os erros positivos e negativos entre os valores previstos e reais, para representar quantas refeições seriam descartadas e quantas estariam em falta se a produção de refeições fosse de acordo com as predições do modelo.
       
  % ----------------------------------------------------------
  % \chapter{METODOLOGIA}
  % ----------------------------------------------------------
  \chapter{Resultados}
	\section{1a Fase Experimental}
	    \subsection{Pré-Processamento}
    	    \subsubsection{Divisão dos conjuntos}
    	        \paragraph{Dificuldades encontradas e resolvidas}
    	            A primeira dificuldade encontrada foi um comportamento anormal dos gráficos de previsão, e valores reais. O conjunto de dados foi lido trocando datas (dia por mês e mês por dia). A indexação por data na divisão de conjuntos produzia divisões fora do formato esperado.\newline
    	            \begin{lstlisting}
    	                df_file = "https://raw.githubusercontent.com/ddlandim/                                     monografy-ann-demand-prediction/master/experimentos_monografia/input/Todos.csv"
                        df = pd.read_csv(df_file,index_col='DATA',parse_dates=True)
                        df.info()
    	            \end{lstlisting}
    	            
    	            Resultado obtido com um dos melhores modelos endógenos GRU, figura: \ref{fig:pandas_wrong_indexing} 
    	            \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/pandas_wrong_indexing.png}
                    	}
                    	\caption{Resultado de um dos melhores modelos endógenos obtido sobre o conjunto de dados aleatoriamente ordenado sobre o tempo \label{fig:pandas_wrong_indexing} }
                    \end{figure}
                    \newpage 
                    Corrigindo a importação dos registros para o formato correto de dados, os resultados foram melhores e condizentes com o comportamento real de consumo, além disso podemos observar que a primeira fase filtra dados obtidos apenas para o 1o semestre de 2019 e no caso da indexação incorreta na figura \ref{fig:pandas_wrong_indexing} a ordenação ultrapassou o mês de julho.
                    \begin{lstlisting}
    	                infile = "https://raw.githubusercontent.com/ddlandim/                           monografy-ann-demand-prediction/master/experimentos_monografia                   /input/Todos.csv"
                        dateparse = lambda x: datetime.strptime(x, '%d/%m/%Y')
                        df = pd.read_csv(infile, parse_dates=['DATA'], date_parser=dateparse,index_col='DATA')
    	            \end{lstlisting}
                    \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/pandas_correct_indexing.png}
                    	}
                    	\caption{Resultado de um dos melhores modelos endógenos obtido sobre o conjunto de dados com ordenação corrigida \label{fig:pandas_correct_indexing} }
                    \end{figure}
                    %%%%
                    %%%%
                    %TODO-T: CITAR FIGURAS
                    Nas figuras \ref{fig:case1_train} , \ref{fig:case1_val} e \ref{fig:case1_test}   são exibidos os valores reais de consumo nos conjuntos de treino (2017 1o e 2o semestre, 2018 2o semestre), validação (2018 - 1o semestre) e teste (2019 - 1o semestre).
                    %TREINO
                    \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/case1_train.png}
                    	}
                    	\caption{Conjunto verdade de treino, dados de 2017 1o e 2o semestre, e 2018 2o semestre. \label{fig:case1_train} }
                    \end{figure}
                    %VALIDACAO
                    \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/case1_val.png}
                    	}
                    	\caption{Conjunto verdade de validação, dados de 2018 1o semestre. \label{fig:case1_val} }
                    \end{figure}
                    %TESTE
                    \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/case1_test.png}
                    	}
                    	\caption{Conjunto verdade de teste, dados de 2019 1o semestre. \label{fig:case1_test} }
                    \end{figure}
                    
    	    \subsubsection{Análise das variáveis endógenas}
    	        \paragraph{Consumo atual em relação às vendas do 1º dia anterior}
    	            \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/case1_consumo_vendas_almoco.png}
                    	}
                    	\caption{Correlação entre consumo e vendas de almoço. \label{fig:case1_consumo_vendas_almoco} }
                    \end{figure}
                    \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/case1_scatter_consumo_vendas_almoco.png}
                    	}
                    	\caption{Gráfico Scatter entre consumo e vendas de almoço. \label{fig:case1_scatter_consumo_vendas_almoco} }
                    \end{figure}
                    Métricas:\newline
                    CONSUMO EM RELAÇÃO ÀS VENDAS DE 1 DIA ANTERIOR\newline
                    CORRELAÇÃO (r): 0.7255528038157009\newline
                    Pi (p) :5.399561176138223e-41\newline
                    RMSE = 260.5399426736619\newline
                    TOTAL DE REFEIÇÕES PROJETADAS = 104694\newline 
                    TOTAL DE REFEIÇÕES CONSUMIDAS = 69544\newline
                    TOTAL DE REFEIÇÕES SUB PROJETADAS = -4703\newline 
                    TOTAL DE REFEIÇÕES SUPER PROJETADAS = 39853\newline 
                    ERRO ABSOLUTO MEDIANO = 139.0\newline 
                    ERRO ABSOLUTO PERCENTUAL MEDIO = 90.18%\newline
                    
        	       É possível notar na figura \ref{fig:case1_consumo_vendas_almoco} que as  vendas de ticket de almoço apresentaram comportamento diferente no ano de 2017 em comparação aos anos seguintes devido à uma limitação imposta pelo restaurante, a partir de 2018, que os alunos comprassem apenas 2 tickets por dia. Possivelmente esta limitação foi dada para aproximar o comportamento de consumo de 1 até 2 dias seguintes à vendas de tickets no dia vigente, esta limitação pode ser interpretada como método de auxílio à gestão para a produção de refeições e para o tratamento de desperdício.
        	        
        	        Mesmo com o outlier presente e com a nova limitação de compras de tickets a partir de 2018, o consumo está fortemente relacionado com as vendas de tickets de 1 dia anterior e que os alunos se adaptaram à utilização em curto prazo dos tickets.
        	        
        	        Há outros fatores não previstos envolvidos, como falha de registros no sistema, bem como o outlier de 2000 vendas realizadas no dia (número superior à população de alunos) pode ser interpretado com a migração de sistema que ocorreu em 2017 da unidade talim para o banco de dados do Hospital São Paulo, possivelmente foram importadas vendas do sistema antigo sem a diferenciação de datas.
        	        
                    Após a normalização dos dados para 3x o desvio padrão médio, o pico de 2000 vendas foi normalizado para o valor arredondado de 1356 refeições e mesmo com a normalização, o comportamento linear desta feature, conforme figura \ref{fig:feature_sem_outliers}, se manteve.
                    \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/feature_sem_outliers.png}
                    	}
                    	\caption{Vendas de tickets normalizados com teto de 3x o desvio padrão. \label{fig:feature_sem_outliers} }
                    \end{figure}
                    E após a aplicação da escala na feature \ref{fig:feature_sem_outliers_escalada}, o comportamento linear também se manteve.
                    \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/feature_sem_outliers_escalada.png}
                    	}
                    	\caption{Vendas de tickets escalada. \label{fig:feature_sem_outliers_escalada} }
                    \end{figure}
                    
                    O processo de normalização e escala foi realizado para todas as features endógenas e para as features climáticas.
                    
    	    \paragraph{Análise da técnica do restaurante}
    	        A análise da técnica do restaurante foi feita com o cálculo de 30\% de produção acima do consumo do 5o dia anterior.
    	        É possível notar que o modelo do R.U é feito para tolerar descartes devido à multa contratual para falta de refeições e o que a produção de 30\% de refeições acima do consumo da semana anterior, conforme a figura  \ref{fig:case1_ru_pred.png}, gera um erro muito maior do que 30\% devido ao comportamento oscilatório do consumo, conforme a figura \ref{fig:case1_ru_pred_scatter}. 
    	         \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/case1_ru_pred.png}
                	}
                	\caption{Correlação entre consumo e produção com 30\% acima do consumo da semana anterior. \label{fig:case1_ru_pred.png} }
                \end{figure}
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/case1_ru_pred_scatter.png}
                	}
                	\caption{Gráfico Scatter entre consumo e produção com margem de 30\%. \label{fig:case1_ru_pred_scatter} }
                \end{figure}
                \paragraph{Consumo atual em relação ao consumo do jantar de 1 dia anterior.}
                    Mesmo se tratando turmas diferentes,  os alunos que consomem refeições no almoço são de período e grade horária diferente dos alunos no período da noite, mas há uma relação evidente entre os 2 consumos, conforme as figuras \ref{fig:case1_consumo_jantar} e \ref{fig:case1_consumo_jantar_scatter}.\newline
                    COMPORTAMENTO DE CONSUMO EM RELAÇÃO À JANTA DE 1 DIA ANTERIOR\newline
                    CORRELAÇÃO (r): 0.765599143585576\newline
                    P-value :4.526981505307197e-48\newline
                    \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/case1_consumo_jantar.png}
                	}
                	\caption{Correlação de consumo de almoço e jantar de 1 dia anterior. \label{fig:case1_consumo_jantar} }
                    \end{figure}
                    \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=1.0\textwidth]{./Figuras/resultados/case1_consumo_jantar_scatter.png}
                    	}
                    	\caption{Gráfico Scatter entre consumo e jantar de 1 dia anterior. \label{fig:case1_consumo_jantar_scatter} }
                    \end{figure}

    	    \subsubsection{Análise da sazonalidade semanal}
    	        Os gráficos a seguir da figura  \ref{fig:case1_violinplot_segunda}, representando a segunda-feira,  até a figura \ref{fig:case1_violinplot_sexta} , representando a sexta-feira,  são gerados para as features categóricas binárias, com a funcionalidade violin-plot da biblioteca seaborn, própria para distribuição de variáveis categóricas-binárias em um dataset.
    	        O violino azul com o valor 1 representa a distribuição do consumo ao logo do dataset.
    	        O violino com valor zero pode ser ignorado e é um retorno padrão da ferramenta, representando a distribuição da ausência de consumo no dia da semana considerado.
    	        Nas sextas feiras, o consumo teve escala de distribuição menor para o primeiro semestre de 2019.
    	         \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_segunda.png}
                	}
                	\caption{Gráfico violino da ditribuição do consumo na segunda feira. \label{fig:case1_violinplot_segunda} }
                \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_terca.png}
                	}
                	\caption{Gráfico violino da ditribuição do consumo na terça feira. \label{fig:case1_violinplot_terca} }
                \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_quarta.png}
                	}
                	\caption{Gráfico violino da ditribuição do consumo na quarta feira. \label{fig:case1_violinplot_quarta} }
                \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_quinta.png}
                	}
                	\caption{Gráfico violino da ditribuição do consumo na quinta feira. \label{fig:case1_violinplot_quinta} }
                \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_sexta.png}
                	}
                	\caption{Gráfico violino da ditribuição do consumo na sexta feira. \label{fig:case1_violinplot_sexta} }
                \end{figure}
    	    \subsubsection{Análise das variáveis exógenas}
    	        \paragraph{Consumo atual em relação ao avanço do semestre}
    	            A correlação do consumo em relação ao avanço do semestre, nos últimos dias do semestre o consumo cairam abruptamente, nota-se uma correlação negativa, mas devido às oscilações de consumo durante o semestre  a correlação não se torna significativa.\newline
    	            COMPORTAMENTO DE CONSUMO EM RELAÇÃO AO AVANÇO DO SEMESTRE\newline 
                    CORRELAÇÃO (r): -0.351388192148681\newline
                    Pi (p) :1.8029942608003656e-08\newline
                    \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_perc_sem.png}
                    	}
                    	\caption{Correlação da ditribuição do consumo com o avanço do semestre. \label{fig:case1_perc_sem} }
                    \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_perc_sem_scatter.png}
                	}
                	\caption{Gráfico escatter da ditribuição do consumo com o avanço do semestre. \label{fig:case1_perc_sem_scatter} }
                \end{figure}
              \paragraph{Consumo atual em relação ao avanço do mês}
                Já o consumo em relação ao avanço do mês é inconclusivo. Esta hipótese validaria que os alunos tivessem preferência de realizar refeições fora do restaurante em períodos típicos de dias de pagamentos geralmente no 5º dia útil, ou todo dia 20. Como o restaurante do ICT Unifesp não enfrenta concorrência dado o isolamento geográfico de seu público, a sazonalidade do consumo se mantém correlata com as atividades da universidade e não da concorrência com outros restaurantes.\newline
                COMPORTAMENTO DE VENDAS EM RELAÇÃO AO AVANÇO DO MÊS\newline
                CORRELAÇÃO (r): 0.04867329355640767\newline
                Pi (p) :0.4500827452374414\newline
                \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_perc_mes.png}
                    	}
                    	\caption{Correlação da ditribuição do consumo com o avanço do mes. \label{fig:case1_perc_mes} }
                    \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_perc_mes_scatter.png}
                	}
                	\caption{Gráfico escatter da ditribuição do consumo com o avanço do mes. \label{fig:case1_perc_mes_scatter} }
                \end{figure}
              \paragraph{Variáveis climáticas}
                As correlações do consumo de refeições com as variáveis climáticas não obtiveram correlações evidentes com o consumo de refeições, sendo observadas nas figuras \ref{fig:case1_temperatura} à \ref{fig:case1_pressao_scatter}.
                %%%%%%%%%%%%%%%%%%%%%%%%%%%  TEMPERATURA   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
                \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_temperatura.png}
                    	}
                    	\caption{Correlação da ditribuição do consumo com a temperatura. \label{fig:case1_temperatura} }
                    \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_temperatura_scatter.png}
                	}
                	\caption{Gráfico escatter da ditribuição do consumo com a temperatura. \label{fig:case1_temperatura_scatter_consumo} }
                \end{figure}
                %%%%%%%%%%%%%%%%%%%%%%%%%%%  UMIDADE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
                 \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_umidade.png}
                    	}
                    	\caption{Correlação da ditribuição do consumo com a umidade. \label{fig:case1_umidade} }
                    \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_umidade_scatter.png}
                	}
                	\caption{Gráfico escatter da ditribuição do consumo com a umidade. \label{fig:case1_temperatura_scatter} }
                \end{figure}
                %%%%%%%%%%%%%%%%%%%%%%%%%%%  VENTO   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
                 \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_vento.png}
                    	}
                    	\caption{Correlação da ditribuição do consumo com a velocidade do vento em m/s. \label{fig:case1_vento} }
                    \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_vento_scatter.png}
                	}
                	\caption{Gráfico escatter da ditribuição do consumo com a velocidade do vento. \label{fig:case1_vento_scatter} }
                \end{figure}
                %%%%%%%%%%%%%%  PRESSAO ATMOSFERICA   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
                 \begin{figure}[!ht]
                    	\center{
                    		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_pressao.png}
                    	}
                    	\caption{Correlação da ditribuição do consumo com a pressão atmosférica. \label{fig:case1_pressao} }
                    \end{figure}
                
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_pressao_scatter.png}
                	}
                	\caption{Gráfico escatter da ditribuição do consumo com a pressão atmosférica. \label{fig:case1_pressao_scatter} }
                \end{figure}
    	\subsection{Definição e treino dos modelos}
    	    \subsubsection{Ajuste empírico de topologia com os modelos perceptron}
    	        %%%%%%%%%%%%%%%%%%%%% MLP 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
              \paragraph{MLP1}
    	        O primeiro modelo perceptron multilayer foi definido com uma camada de 15 unidades (mesmo número de features endógenas sendo 5 para consumo almoço (de 1 a 5 dias anteriores para cada entrada), 5 para vendas de tickets e 5 para consumo de jantar.
    	        O modelo será denominado MLP1 para futuras referências.
    	        \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_mlp1.png}
                	}
                	\caption{Topologia do modelo MLP1 \label{fig:case1_mlp1} }
                \end{figure}
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_mlp1_train.png}
                	}
                	\caption{Gráfico de treino do modelo MLP1. \label{fig:case1_mlp1_train} }
                \end{figure}
    	        A raiz do erro quadrático médio do modelo foi, RMSE = 130.6207420543897
    	        
    	        %%%%%%%%%%%%%%%%%%%%% MLP 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    	        \paragraph{MLP2}
    	        Foi definido um novo modelo MLP2, aumentando o número de neurônios do MLP1 para a comparação do RMSE de treino.
    	        \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_mlp2.png}
                	}
                	\caption{Topologia do modelo MLP2 \label{fig:case1_mlp2} }
                \end{figure}
                \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_mlp2_train.png}
                	}
                	\caption{Gráfico de treino do modelo MLP2. \label{fig:case1_mlp2_train} }
                \end{figure}
                 A raiz do erro quadrático médio do modelo MLP2 foi, RMSE = 107.97413966672336
    	        É possível notar a diminuição do RMSE (Raiz do erro quadrático médio) ao aumentar a profundidade da rede perceptron para treino e avaliação sob o conjunto de validação. Validando a hipótese de que os modelos tem capacidade de aprendizado do problema em relação ao ajuste da topologia dos mesmos.
    	        As figuras de topologia e treino dos modelos vão de \ref{fig:case1_mlp1} à \ref{fig:case1_mlp2_train}.
    	    %%%%%%%%%%%%%%%%%%%%% MODELOS ENDÓGENOS ... VAMO LÁ ... TÁ ACABANDO ... %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
          \subsubsection{Modelos Endógenos}
    	        Como o ajuste empírico obteve avanço nos resultados, foi definido outro modelo perceptron MLP\_ENDO\_1 com maior profundidade, e depois um modelo recorrente GRU com 2 reajustes (RNN\_ENDO\_1 e RNN\_ENDO\_2).
                Para a avaliação prévia dos modelos, os mesmos foram testados no conjunto de validação.
    	        %%%%%%%%%%%%%%%%% MLP ENDO 1
              \paragraph{MLP\_ENDO\_1}
      	        \begin{figure}[!ht]
                	\center{
                		\includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_mlp_endo1.png}
                	}
                	\caption{Topologia do modelo MLP\_ENDO\_1 \label{fig:case1_mlp_endo1} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_mlp_endo1_train.png}
                  }
                  \caption{Treino do modelo MLP\_ENDO\_1 \label{fig:case1_mlp_endo1_train} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_mlp_endo1_val.png}
                  }
                  \caption{Avaliação do modelo MLP\_ENDO\_1 \label{fig:case1_mlp_endo1_val} }
                \end{figure}
                METRICAS DO MODELO MLP\_ENDO\_1 : \newline
                RMSE = 110.92902359567118\newline
                TOTAL DE REFEIÇÕES PROJETADAS = 89 : 33611.37430477142\newline
                TOTAL DE REFEIÇÕES CONSUMIDAS = 89 : 35555\newline
                TOTAL DE REFEIÇÕES SUB PROJETADAS = -4328.862397193909\newline
                TOTAL DE REFEIÇÕES SUPER PROJETADAS = 2385.236701965332\newline

              %%%%%%%%%%%%%%%%% RNN ENDO 1
              \paragraph{RNN\_ENDO\_1}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_endo1.png}
                  }
                  \caption{Topologia do modelo RNN\_ENDO\_1 \label{fig:case1_rnn_endo1} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_endo1_train.png}
                  }
                  \caption{Treino do modelo RNN\_ENDO\_1 \label{fig:case1_rnn_endo1_train} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_endo1_val.png}
                  }
                  \caption{Avaliação do modelo RNN\_ENDO\_1 \label{fig:case1_rnn_endo1_val} }
                \end{figure}
                METRICAS DO MODELO RNN\_ENDO\_1 : \newline
                RMSE = 118.98273426840373\newline
                TOTAL DE REFEIÇÕES PROJETADAS = 33423.96739196777\newline
                TOTAL DE REFEIÇÕES CONSUMIDAS = 35555\newline
                TOTAL DE REFEIÇÕES SUB PROJETADAS = -5248.0078125\newline
                TOTAL DE REFEIÇÕES SUPER PROJETADAS = 3116.9752044677734\newline

            %%%%%%%%%%%%%%%%% RNN ENDO 2
              \paragraph{RNN\_ENDO\_2}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_endo2.png}
                  }
                  \caption{Topologia do modelo RNN\_ENDO\_2 \label{fig:case1_rnn_endo2} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_endo2_train.png}
                  }
                  \caption{Treino do modelo RNN\_ENDO\_2 \label{fig:case1_rnn_endo2_train} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_endo2_val.png}
                  }
                  \caption{Avaliação do modelo RNN\_ENDO\_2 \label{fig:case1_rnn_endo2_val} }
                \end{figure}
                METRICAS DO MODELO RNN\_ENDO\_2 : \newline
                RMSE = 109.81020024143946\newline
                TOTAL DE REFEIÇÕES PROJETADAS = 32984.970529556274\newline
                TOTAL DE REFEIÇÕES CONSUMIDAS = 35555\newline
                TOTAL DE REFEIÇÕES SUB PROJETADAS = -4821.583518981934\newline
                TOTAL DE REFEIÇÕES SUPER PROJETADAS = 2251.554048538208\newline

                \paragraph{Comparativo gráfico da etapa de avaliação no teste no conjunto de validação, entre os melhores modelos endógenos treinados, RNN\_ENDO\_2 e MLP\_ENDO\_1}
                  É possível notar, conforme figura \ref{fig:case1_gru_mlp_val_analise} que mesmo com correlação e RMSE muito próximo nos 2 modelos, o modelo GRU apresentou melhor valor p-value, no calculo de correlação de Pearson*. 
                  Em Junho após uma ocorrência outlier, o modelo GRU teve melhor recuperação de resultados em comparação ao MLP.
                  De acordo com a referência da documentação da biblioteca scipy, O valor p indica aproximadamente a probabilidade de um sistema não correlacionado produzir conjuntos de dados que têm uma correlação de Pearson pelo menos tão extrema quanto a calculada a partir desses conjuntos de dados.\newline
                  RNN\_ENDO\_2 : CORRELAÇÃO (r): 0.6753384458677313 Pi (p) :3.903678433027079e-13\newline
                  MLP\_ENDO\_1 : MLP: CORRELAÇÃO (r): 0.6791684214084684 Pi (p) :2.5590689588089596e-13\newline
                  \begin{figure}[!ht]
                      \center{
                        \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_gru_mlp_val_analise.PNG}
                      }
                      \caption{Comparação da etapa de validação entre MLP\_ENDO\_1 e RNN\_ENDO\_1 \label{fig:case1_gru_mlp_val_analise} }
                    \end{figure}

          %%%%%%%%%%%%%%%%%%%%% MODELOS EXÓGENOS ... 2 DA MANHÃ... Q Q EU FUI INVENTAR NESSE TRABALHO ... %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    	    \subsubsection{Modelos mistos endógenos e exógenos}
            %%%%%%%%%%%%%%%%% RNN_EXO_1
              \paragraph{RNN\_EXO\_1}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_1.png}
                  }
                  \caption{Topologia do modelo RNN\_EXO\_1 \label{fig:case1_rnn_exo_1} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_1_train.png}
                  }
                  \caption{Treino do modelo RNN\_EXO\_1 \label{fig:case1_rnn_exo_1_train} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_1_val.png}
                  }
                  \caption{Avaliação do modelo RNN\_EXO\_1 \label{fig:case1_rnn_exo_1_val} }
                \end{figure}
                
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_1_val_scatter.png}
                  }
                  \caption{Grafico scatter de avaliação do modelo RNN\_EXO\_1 \label{fig:case1_rnn_exo_1_val_scatter} }
                \end{figure}
                METRICAS DO MODELO RNN\_EXO\_1 : \newline
                RMSE = 132.9496\newline
                TOTAL DE REFEIÇÕES PROJETADAS = 30223.764709472656\newline
                TOTAL DE REFEIÇÕES CONSUMIDAS = 35555\newline
                TOTAL DE REFEIÇÕES SUB PROJETADAS = -7585.754409790039\newline
                TOTAL DE REFEIÇÕES SUPER PROJETADAS = 2254.5191192626953\newline

              %%%%%%%%%%%%%%%%% RNN_EXO_2
              \paragraph{RNN\_EXO\_2}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_2.png}
                  }
                  \caption{Topologia do modelo RNN\_EXO\_2 \label{fig:case1_rnn_exo_2} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_2_train.png}
                  }
                  \caption{Treino do modelo RNN\_EXO\_2 \label{fig:case1_rnn_exo_2_train} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_2_val.png}
                  }
                  \caption{Avaliação do modelo RNN\_EXO\_2 \label{fig:case1_rnn_exo_2_val} }
                \end{figure}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_2_val_scatter.png}
                  }
                  \caption{Grafico scatter de avaliação do modelo RNN\_EXO\_2 \label{fig:case1_rnn_exo_2_val_scatter} }
                \end{figure}
                METRICAS DO MODELO RNN\_EXO\_2 : \newline
                RMSE = 122.32142544582184\newline
                TOTAL DE REFEIÇÕES PROJETADAS = 32146.112915039062\newline
                TOTAL DE REFEIÇÕES CONSUMIDAS = 35555\newline
                TOTAL DE REFEIÇÕES SUB PROJETADAS = -5875.795913696289\newline
                TOTAL DE REFEIÇÕES SUPER PROJETADAS = 2466.9088287353516\newline

          %%%%%%%%%%%%%%%%% RNN_EXO_3
              \paragraph{RNN\_EXO\_3}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_3.png}
                  }
                  \caption{Topologia do modelo RNN\_EXO\_3 \label{fig:case1_rnn_exo_3} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_3_train.png}
                  }
                  \caption{Treino do modelo RNN\_EXO\_3 \label{fig:case1_rnn_exo_3_train} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_3_val.png}
                  }
                  \caption{Avaliação do modelo RNN\_EXO\_3 \label{fig:case1_rnn_exo_3_val} }
                \end{figure}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_3_val_scatter.png}
                  }
                  \caption{Grafico scatter de avaliação do modelo RNN\_EXO\_3 \label{fig:case1_rnn_exo_3_val_scatter} }
                \end{figure}
                METRICAS DO MODELO RNN\_EXO\_3 : \newline
                RMSE = 121.25903250027721\newline
                TOTAL DE REFEIÇÕES PROJETADAS = 35003.56196594238\newline
                TOTAL DE REFEIÇÕES CONSUMIDAS = 35555\newline
                TOTAL DE REFEIÇÕES SUB PROJETADAS = -4471.480010986328\newline
                TOTAL DE REFEIÇÕES SUPER PROJETADAS = 3920.041976928711\newline
        \newpage
    	\subsection{Teste e métricas}
    	    \subsubsection{Endógenos : GRU x MLP}
            Podemos notar na figura \ref{fig:case1_mlp_endo1_test} e \ref{fig:case1_rnn_endo2_test} que apesar dos coeficientes de correlação próximos no teste entre os modelos RNN\_ENDO\_2 e MLP\_ENDO\_1 impactando na proximidade de outras métricas como RMSE, MAPE, etc. O valor p-value é notoriamente discrepante.\newline
            Resultados dos modelos RNN\_ENDO\_2 X MLP\_ENDO\_1:\newline
            RNN\_ENDO\_2 : CORRELAÇÃO (r): 0.5954398951050144 Pi (p) :9.422151772316392e-10\newline
            MLP\_ENDO\_1 : MLP: CORRELAÇÃO (r): 0.5212411617024483 Pi (p) :1.9211576129056944e-07 \newline
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_mlp_endo1_test.png}
              }
              \caption{Teste MLP\_ENDO\_1 \label{fig:case1_mlp_endo1_test} }
            \end{figure}

            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_endo2_test.png}
              }
              \caption{Teste RNN\_ENDO\_2 \label{fig:case1_rnn_endo2_test} }
            \end{figure}

    	    \subsubsection{Melhor modelo Endógeno}
            De acordo com as métricas de teste, o melhor modelo endógeno foi o RNN\_ENDO\_2, e suas anomalias de previsão são devidamente justificadas por datas especiais no calendário do primeiro semestre:
            
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_endo2_test_dates.png}
              }
              \caption{Analise de anomalias preditivas do RNN\_ENDO\_2 \label{fig:case1_rnn_endo2_test_dates} }
            \end{figure}
            
            As datas que produziram outliers e anomalias de predição no melhor modelo exógeno, podem ser observadas na figura \ref{fig:case1_rnn_endo2_test_dates}, sendo os pontos verdes outliers onde o modelo seguiu a tendência de alta ou baixa de consumo mas obteve erro discrepante, e nos pontos vermelhos seguiu tendência inversa:\newline
            
            Data : 01/03/2019 (sexta feira)    | Consumo : 224 | Justificativa : Sexta Feira pré - carnaval\newline
            Data : 03/06/2019 (segunda feira)  | Consumo : 13  | Justificativa : Segunda Feira pós paralisação estudantil na praça afonso pena\newline

            Datas com anomalias de previsão onde o modelo seguiu tendência oposta ao consumo, pontos vermelhos:\newline

            Data : 08/03/2019 (sexta feira)    | Consumo : 209 | Justificativa : Sexta Feira pós - carnaval\newline
            Data : 15/05/2019 (quarta feira)   | Consumo : 19  | Justificativa : Paralisação estudantil na praça afonso pena\newline
            Data : 30/05/2019 (quinta feira)   | Consumo : 38  | Justificativa : Paralisação estudantil na praça afonso pena\newline

            Métricas do melhor modelo, RNN\_ENDO\_2:\newline
            Total\_Consumidas = 31962 | Total\_Previstas = 31465,61133 | Erro\_Total\_Previsao = -496,3886719 | Percentual\_Erro\_Total = -1,5530\%\newline
            Correlação = 0,595439895 | P-value = 9,42215E-10         | RMSE = 108,0663015\newline
            Total de Refeições em falta = -2982,567947 | Total Descartadas = 3478,957266\newline
            ERRO\_ABS\_MEDIANO = 46,70721436 | ERRO\_ABSOLUTO\_PERCENTUAL\_MEDIO = 74,93539002\newline
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_endo2_test_scatter.png}
              }
              \caption{Grafico scatter de teste do RNN\_ENDO\_2 \label{fig:case1_rnn_endo2_test_scatter} }
            \end{figure}
    	    \subsubsection{Modelos mistos}
             %%%%%%%%%%%%%%%%% RNN_EXO\_1
              \paragraph{RNN\_EXO\_1}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_1_test.png}
                  }
                  \caption{Teste do modelo RNN\_EXO\_1 \label{fig:case1_rnn_exo_1_test} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_1_test_scatter.png}
                  }
                  \caption{Grafico scatter de teste do modelo RNN\_EXO\_1 \label{fig:case1_rnn_exo_1_test_scatter} }
                \end{figure}
                RNN\_EXO\_1:
                TOTAL DE REFEIÇÕES CONSUMIDAS = 31962 : 88 linhas \newline
                TOTAL DE REFEIÇÕES PROJETADAS = 28728.816 : 88 linha \newline
                ERRO DE PREVISÃO = -3233.18359375 -10.115711137444466\% do total consumido\newline
                CORRELAÇÃO (r): 0.4122158648305426 Pi (p) :6.590759241637016e-05 R2 :0.16992191921799218\newline
                RMSE = 124.49076120428357\newline
                ERRO TOTAL DE REFEIÇÕES SUB PROJETADAS = -2709.1732788085938\newline
                ERRO TOTAL DE REFEIÇÕES SUPER PROJETADAS = 5942.356475830078\newline
                ERRO ABSOLUTO MEDIANO = 85.59107971191406\newline
                ERRO ABSOLUTO PERCENTUAL MEDIO = 90.98694558104974\%\newline
             %%%%%%%%%%%%%%%%% RNN_EXO_2
              \paragraph{RNN\_EXO\_2}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_2_test.png}
                  }
                  \caption{Teste do modelo RNN\_EXO\_2 \label{fig:case1_rnn_exo_2_test} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_2_test_scatter.png}
                  }
                  \caption{Grafico scatter de teste do modelo RNN\_EXO\_2 \label{fig:case1_rnn_exo_2_test_scatter} }
                \end{figure}
                RNN\_EXO\_2:
                TOTAL DE REFEIÇÕES CONSUMIDAS = 31962 : 88 linhas\newline
                TOTAL DE REFEIÇÕES PROJETADAS = 30823.148 : 88 linhas\newline
                ERRO DE PREVISÃO = -1138.8515625 -3.563142364370189\% do total consumido\newline
                CORRELAÇÃO (r): 0.5206433612135913 Pi (p) :1.995208420251518e-07 R2 :0.27106950957578635\newline
                RMSE = 112.99211377165491\newline
                ERRO TOTAL DE REFEIÇÕES SUB PROJETADAS = -3044.8834533691406\newline
                ERRO TOTAL DE REFEIÇÕES SUPER PROJETADAS = 4183.734128952026\newline
                ERRO ABSOLUTO MEDIANO = 63.59894561767578\newline
                ERRO ABSOLUTO PERCENTUAL MEDIO = 88.26875085831726\%\newline
             %%%%%%%%%%%%%%%%% RNN_EXO_3
              \paragraph{RNN\_EXO\_3}
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_3_test.png}
                  }
                  \caption{Teste do modelo RNN\_EXO\_3 \label{fig:case1_rnn_exo_3_test} }
                \end{figure}

                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_rnn_exo_3_test_scatter.png}
                  }
                  \caption{Grafico scatter de teste do modelo RNN\_EXO\_3 \label{fig:case1_rnn_exo_3_test_scatter} }
                \end{figure}
                RNN\_EXO\_3:
                TOTAL DE REFEIÇÕES CONSUMIDAS = 31962 : 88 linhas\newline
                TOTAL DE REFEIÇÕES PROJETADAS = 29425.791 : 88 linhas\newline
                ERRO DE PREVISÃO = -2536.208984375 -7.935075978896815\% do total consumido\newline
                CORRELAÇÃO (r): 0.33963283016931 Pi (p) :0.0012067360859947137 R2 :0.11535045932881538\newline
                RMSE = 124.65810037942255\newline
                ERRO TOTAL DE REFEIÇÕES SUB PROJETADAS = -3417.6602630615234\newline
                ERRO TOTAL DE REFEIÇÕES SUPER PROJETADAS = 5953.868759155273\newline
                ERRO ABSOLUTO MEDIANO = 100.44429016113281\newline
                ERRO ABSOLUTO PERCENTUAL MEDIO = 98.79064922123037\%\newline

    	    \subsubsection{Melhor modelo da 1a fase}
                Entre todos os modelos, o melhor modelo, produzindo o menor RMSE, e com vantagem em todas as outras métricas foi o modelo endógeno, RNN\_ENDO\_2, ressaltando que o gráfico de predições deste modelo se encontra na figura \ref{fig:case1_rnn_endo2_test}
                Comparativos finais:
               %TODO: INSERIR TABELA COMPARATIVOS FINAIS.

    \section{2a Fase Experimental}
	    \subsection{Pré-Processamento}
    	    \subsubsection{Divisão dos conjuntos}
    	        %%% TREINO
    	        \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_train.png}
                  }
                  \caption{Conjunto de dados de treino, ano de 2017 completo \label{fig:case2_train} }
                \end{figure}
                
                %%% VALIDAÇÃO
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_val.png}
                  }
                  \caption{Conjunto de dados de validação, ano de 2018 completo \label{fig:case2_val} }
                \end{figure}
                
                %%% TESTE
                \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_test.png}
                  }
                  \caption{Conjunto de dados de teste, ano de 2019 completo \label{fig:case2_test} }
                \end{figure}
    	        
    	        A nova divisão dos conjuntos segue conforme as figuras \ref{fig:case2_train} para o conjunto de treino, \ref{fig:case2_train} para o conjunto de validação e \ref{fig:case2_train} para o conjunto de teste.
    	        
    	    \subsubsection{Análise da técnica do restaurante}
    	        \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_ru_pred.png}
                  }
                  \caption{Gráfico entre o consumo de refeições e a produção com margem de 30\% para o ano de 2019 completo. \label{fig:ru_pred} }
                \end{figure}
                 \begin{figure}[!ht]
                  \center{
                    \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case1_ru_pred_scatter.png}
                  }
                  \caption{Gráfico scatter entre o consumo de refeições e a produção com margem de 30\% para o ano de 2019 completo. \label{fig:ru_pred_scatter} }
                \end{figure}
                Para a produção de refeições com margem de 30\% acima do consumo do 5o dia anterior, conforme figura \ref{fig:ru_pred} e \ref{fig:ru_pred_scatter} obtemos as seguintes métricas:\newline
                TOTAL DE REFEIÇÕES CONSUMIDAS = 58653 : 182 linhas \newline
                TOTAL DE REFEIÇÕES PROJETADAS = 76262 : 182 linhas CORRELAÇÃO (r): 0.40067947341844423 \newline
                Pi (p) :2.0845891721642294e-08\newline
                RMSE = 191.7620291511743 \newline
                TOTAL DE REFEIÇÕES SUPER PROJETADAS = 23412 \newline
                TOTAL DE REFEIÇÕES SUB PROJETADAS = -5803 \newline
                ERRO ABSOLUTO MEDIANO = 133.0 \newline
                ERRO ABSOLUTO PERCENTUAL MEDIO = 205.61135949728225\% \newline
    	\subsection{Treino e Validação dos modelos}
    	    %%% MLP_ENDO_1
    	    \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_mlp_endo1_train.png}
              }
              \caption{Gráfico de treino do modelo MLP\_ENDO\_1. \label{fig:case2_mlp_endo1_train} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_mlp_endo1_val.png}
              }
              \caption{Gráfico de validação do modelo MLP\_ENDO\_1. \label{fig:case2_mlp_endo1_val} }
            \end{figure}
            
            %%% RNN_ENDO_1
    	    \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_endo1_train.png}
              }
              \caption{Gráfico de treino do modelo RNN\_ENDO\_1. \label{fig:case2_rnn_endo1_train} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_endo1_val.png}
              }
              \caption{Gráfico de validação do modelo RNN\_ENDO\_1. \label{fig:case2_rnn_endo1_val} }
            \end{figure}
            
             %%% RNN_ENDO_2
    	    \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_endo2_train.png}
              }
              \caption{Gráfico de treino do modelo RNN\_ENDO\_2. \label{fig:case2_rnn_endo2_train} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_endo2_val.png}
              }
              \caption{Gráfico de validação do modelo RNN\_ENDO\_2. \label{fig:case2_rnn_endo2_val} }
            \end{figure}
            
            %%% RNN_EXO_1
    	    \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo1_train.png}
              }
              \caption{Gráfico de treino do modelo RNN\_EXO\_1. \label{fig:case2_rnn_exo1_train} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo1_val.png}
              }
              \caption{Gráfico de validação do modelo  RNN\_EXO\_1. \label{fig:case2_rnn_exo1_val} }
            \end{figure}
            
            %%% RNN_EXO_2
    	    \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo2_train.png}
              }
              \caption{Gráfico de treino do modelo RNN\_EXO\_2. \label{fig:case2_rnn_exo2_train} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo2_val.png}
              }
              \caption{Gráfico de validação do modelo  RNN\_EXO\_2. \label{fig:case2_rnn_exo2_val} }
            \end{figure}
            
            %%% RNN_EXO_3
    	    \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo3_train.png}
              }
              \caption{Gráfico de treino do modelo RNN\_EXO\_3. \label{fig:case2_rnn_exo3_train} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo3_val.png}
              }
              \caption{Gráfico de validação do modelo  RNN\_EXO\_3. \label{fig:case2_rnn_exo3_val} }
            \end{figure}
            
    	    Nesta etapa experimental, todos os modelos foram definidos com a mesma topologia da primeira fase.
    	    Os modelos endógenos obtiveram melhoria nos resultados avaliados sobre o conjunto de validação.
    	    Já os modelos exógenos, apenas 1 obteve melhoria significativa nos resultados, o modelo RNN\_EXO\_1, porém os outros obtiveram resultados anômalos no plot dos gráficos de treino e validação.
    	    Os gráficos de treino e validação podem ser conferidos da figura \ref{fig:case2_mlp_endo1_train} à figura \ref{fig:case2_rnn_exo3_val}
    	    MÉTRICAS:\newline
    	    MLP\_ENDO\_1 \newline
            TOTAL DE REFEIÇÕES CONSUMIDAS = 65637 : 184 linhas\newline
            TOTAL DE REFEIÇÕES PROJETADAS = 62781.324 : 184 linhas\newline
            CORRELAÇÃO (r): 0.7649396511306203 Pi (p) :1.3054591862307924e-36\newline
            RMSE = 89.32526704475531\newline
            TOTAL DE REFEIÇÕES SUB PROJETADAS = -4257.537273406982\newline
            TOTAL DE REFEIÇÕES SUPER PROJETADAS = 7113.216419219971\newline
            ERRO ABSOLUTO MEDIANO = 47.23118591308594\newline
            ERRO ABSOLUTO PERCENTUAL MEDIO = 3234942340.243013\% \newline
            
            RNN\_ENDO\_1\newline
            TOTAL DE REFEIÇÕES CONSUMIDAS = 65637 : 184 linhas\newline
            TOTAL DE REFEIÇÕES PROJETADAS = 65219.613 : 184 linhas\newline
            CORRELAÇÃO (r): 0.7538102329191316 Pi (p) :5.014834155014456e-35\newline
            RMSE = 89.73281442880939\newline
            TOTAL DE REFEIÇÕES SUB PROJETADAS = -5666.187889099121\newline
            TOTAL DE REFEIÇÕES SUPER PROJETADAS = 6083.576965332031\newline
            ERRO ABSOLUTO MEDIANO = 48.55305480957031\newline
            ERRO ABSOLUTO PERCENTUAL MEDIO = 4145884336.345922\% \newline
            
            RNN\_ENDO\_2\newline
            TOTAL DE REFEIÇÕES CONSUMIDAS = 65637 : 184 linhas\newline
            TOTAL DE REFEIÇÕES PROJETADAS = 64170.63 : 184 linhas\newline
            CORRELAÇÃO (r): 0.6606462451035008 Pi (p) :1.9184607118463233e-24\newline
            RMSE = 102.80909876605612\newline
            TOTAL DE REFEIÇÕES SUB PROJETADAS = -6437.710876464844\newline
            TOTAL DE REFEIÇÕES SUPER PROJETADAS = 7904.081573486328\newline
            ERRO ABSOLUTO MEDIANO = 61.39728546142578\newline
            ERRO ABSOLUTO PERCENTUAL MEDIO = 4124092635.50105\% \newline
            
            RNN\_EXO\_1\newline
            RMSE:  109.97634427462593\newline
            TOTAL DE REFEIÇÕES CONSUMIDAS = 65637 : 184 linhas\newline
            TOTAL DE REFEIÇÕES PROJETADAS = 62530.465 : 184 linhas\newline
            CORRELAÇÃO (r): 0.6052852633603059 Pi (p) :8.961737817855194e-20\newline
            RMSE = 109.97634427462593\newline
            TOTAL DE REFEIÇÕES SUB PROJETADAS = -6378.557273864746\newline
            TOTAL DE REFEIÇÕES SUPER PROJETADAS = 9485.092361450195\newline
            ERRO ABSOLUTO MEDIANO = 67.952392578125\newline
            ERRO ABSOLUTO PERCENTUAL MEDIO = 3590946402.38917\% \newline
            
            RNN\_EXO\_2\newline
            RMSE:  373.5611599422393\newline
            TOTAL DE REFEIÇÕES CONSUMIDAS = 65637 : 184 linhas\newline
            TOTAL DE REFEIÇÕES PROJETADAS = 1656.0 : 184 linhas\newline
            CORRELAÇÃO (r): nan Pi (p) :nan\newline
            RMSE = 373.5611599422393\newline
            TOTAL DE REFEIÇÕES SUB PROJETADAS = -18.0\newline
            TOTAL DE REFEIÇÕES SUPER PROJETADAS = 63999.0\newline
            ERRO ABSOLUTO MEDIANO = 380.0\newline
            ERRO ABSOLUTO PERCENTUAL MEDIO = 97826180.62563947\% \newline
            
            RNN\_EXO\_3\newline
            RMSE:  131.93314687496996\newline
            TOTAL DE REFEIÇÕES CONSUMIDAS = 65637 : 184 linhas\newline
            TOTAL DE REFEIÇÕES PROJETADAS = 59270.867 : 184 linhas\newline
            CORRELAÇÃO (r): 0.3675645280265282 Pi (p) :2.8557023726066666e-07\newline
            RMSE = 131.93314687496996\newline
            TOTAL DE REFEIÇÕES SUB PROJETADAS = -6869.128311157227\newline
            TOTAL DE REFEIÇÕES SUPER PROJETADAS = 13235.260711669922\newline
            ERRO ABSOLUTO MEDIANO = 101.04127502441406\newline
            ERRO ABSOLUTO PERCENTUAL MEDIO = 3493320353.99382\% \newline
    	    
    	    
    	\subsection{Teste e métricas}
            %%% MLP_ENDO_1
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_mlp_endo1_test.png}
              }
              \caption{Gráfico de teste do modelo MLP\_ENDO\_1. \label{fig:case2_mlp_endo1_test} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_mlp_endo1_test_scatter.png}
              }
              \caption{Gráfico de scatter do modelo MLP\_ENDO\_1. \label{fig:case2_mlp_endo1_test_scatter} }
            \end{figure}
              
            %%% RNN_ENDO_1
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_endo1_test.png}
              }
              \caption{Gráfico de teste do modelo RNN\_ENDO\_1. \label{fig:case2_rnn_endo1_test} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_endo1_test_scatter.png}
              }
              \caption{Gráfico de scatter do modelo RNN\_ENDO\_1. \label{fig:case2_rnn_endo1_test_scatter} }
            \end{figure}
              
             %%% RNN_ENDO_2
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_endo2_test.png}
              }
              \caption{Gráfico de teste do modelo RNN\_ENDO\_2. \label{fig:case2_rnn_endo2_test} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_endo2_test_scatter.png}
              }
              \caption{Gráfico de scatter do modelo RNN\_ENDO\_2. \label{fig:case2_rnn_endo2_test_scatter} }
            \end{figure}
              
            %%% RNN_EXO_1
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo1_test.png}
              }
              \caption{Gráfico de teste do modelo RNN\_EXO\_1. \label{fig:case2_rnn_exo1_test} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo1_test_scatter.png}
              }
              \caption{Gráfico de scatter do modelo  RNN\_EXO\_1. \label{fig:case2_rnn_exo1_test_scatter} }
            \end{figure}
              
            %%% RNN_EXO_2
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo2_test.png}
              }
              \caption{Gráfico de teste do modelo RNN\_EXO\_2. \label{fig:case2_rnn_exo2_test} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo2_test_scatter.png}
              }
              \caption{Gráfico de scatter do modelo  RNN\_EXO\_2. \label{fig:case2_rnn_exo2_test_scatter} }
            \end{figure}
              
            %%% RNN_EXO_3
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo3_test.png}
              }
              \caption{Gráfico de teste do modelo RNN\_EXO\_3. \label{fig:case2_rnn_exo3_test} }
            \end{figure}
            \begin{figure}[!ht]
              \center{
                \includegraphics[width=0.7\textwidth]{./Figuras/resultados/case2/case2_rnn_exo3_test_scatter.png}
              }
              \caption{Gráfico de scatter do modelo  RNN\_EXO\_3. \label{fig:case2_rnn_exo3_test_scatter} }
\end{figure}
    	    Após o teste de todos os modelos da 2a fase, o modelo que obteve as melhores métricas entre todos, foi RNN\_EXO\_2, onde o gráfico de predições e scatter podem ser conferidos na figura \ref{fig:case2_mlp_endo1_test}.
    	    Todos os gráficos de teste estão entre a figura \ref{fig:case2_mlp_endo1_test} à \ref{fig:case2_rnn_exo3_test_scatter}
    	    \subsubsection{Teste do melhor modelo da 2a fase no domínio da primeira fase}
    	        
    	        
    	        Como o melhor modelo obtido na 2a fase, se saiu melhor do que o melhor modelo da primeira fase, foi feito um novo teste do modelo RNN\_EXO\_1 com o domínio de testes restrito para o primeiro semestre (domínio da primeira fase) a fim de uma comparação justa com o melhor modelo da primeira fase, o RNN\_ENDO\_2.
    	        
    
    \section{Tabela de resultados}
        \subsection{Melhores Resultados}
            %TODO: INCLUIR PLANILHA METRICAS TESTE FINAIS, ABA MELHORES MODELOS
        \subsection{Tabela completa de todos os modelos}
            %TODO: INCLUIR PLANILHA METRICAS TESTE FINAIS, ABA TODOS
	    
  % ----------------------------------------------------------
  % \chapter{Plano de atividades para o TCC II}
  % ----------------------------------------------------------
  \chapter{Conclusão}
    \section{A importância da metodologia de divisão do conjunto de dados em séries temporais}
        Como estamos trabalhando com um conjunto de dados com todas as features e targets de sazonalidade temporal, é notório que a ordenação dos dados na separação do conjunto em treino, teste e validação deve seguir uma ordem cronológica para os modelos aprenderem com o passado e realizarem predições para o futuro. 
        O erro na divisão identificado no capitulo de divisão do conjunto de dados, demonstrado com erros na figura \ref{fig:pandas_wrong_indexing} e depois corrigido conforme a figura \ref{fig:pandas_correct_indexing} demonstra esta conclusão.

    \section{Sobre o método de produção de refeições com margem de erro e análise da semana anterior}
        Mesmo com a produção de 30\% acima do consumo na semana anterior, no fim de cada semestre, o restaurante do ICT Unifesp descarta mais do que 30\%, pois o comportamento oscilatório do consumo e o acréscimo de outliers, acaba ampliando o erro. No ano de 2019, seguindo este método, 23 mil refeições foram descartas.
        O Modelo RNN\_EXO\_3 que trouxe o maior descarte entre todos os 12 modelos testados, realizou 8914 descartes.
        Isso evidencia a necessidade de se implementar métodos eficientes para a produção e planejamento de refeições no restaurante universitário da Unifesp.
    
    \section{Sobre a sazonalidade semanal}
        Em todo o conjunto de dados, nos dias da semana, a sexta feira é o dia de menor consumo independente do período do ano. Já as datas de terça e quinta concentram a maior movimentação de consumo.
    
    \section{Sobre o ajuste empírico da topologia dos modelos}
        Na etapa de validação dos primeiros modelos desenvolvidos, demonstrado na subseção Ajuste empírico de topologia da 1a fase, conforme figuras \ref{fig:case1_mlp1_train} e \ref{fig:case1_mlp2_train} capítulo de resultados da 1a fase, foi possível notar a diminuição do RMSE (Raiz do erro quadrático médio) ao aumentar a profundidade da rede Perceptron para treino e avaliação sob o conjunto de validação. Validando a hipótese de que os modelos tem capacidade de aprendizado do problema em relação ao ajuste da topologia dos mesmos.
        
    \section{Sobre os resultados preliminares da etapa de validação}
        Apesar de valores de correlação muito próximos, Foi possível notar na 1a fase algumas diferenças gráficas entre o modelo RNN\_ENDO\_2 e o modelo `MLP\_ENDO\_1 na etapa de validação dos modelos.  Porém na etapa de testes, o modelo  RNN\_ENDO\_2 obteve RMSE 108 e correlação de 0,59 enquanto o MLP obteve RMSE de 128 e correlação de 0,52. Evidenciando que métricas muito próximas, entre modelos, na etapa de teste sobre o conjunto de validação pode evidenciar que não devemos realizar uma seleção previa destes modelos para a etapa de testes, sendo necessário o teste dos 2 modelos para comparações finais. Já os modelos que apresentaram diferenças de RMSE discrepantes na etapa de validação, mantiveram essas diferenças (para o pior e o melhor) na etapa de testes.

    \section{Sobre os erros anômalos de predição}
        Apesar do conjunto de dados conter 2 features que informam a distancia em dias para o próximo registro e o registro anterior para os modelos identificarem feriados e recessos prolongados, alguns eventos no calendário como paralisações, não são muito bem representados por tais features, indicando a necessidade de mais pesquisa de features que possam representar melhor este comportamento.

    \section{Sobre o modelo com melhor resultado}
        No primeiro split, com validação restrita ao primeiro semestre de 2018, os modelos endógenos se saíram melhor do que os modelos mistos. Isso pode significar que as features exógenas (onde a maioria tem sazonalidade anual como as climáticas limitadas às estações do ano) foram ruidosas no aprendizado.
        Para o modelo RNN\_EXO\_1 da 2a fase, se saindo melhor que todos os modelos deste trabalho, algumas melhorias são indicadas para os trabalhos futuros.\newline
        AUMENTAR O CONJUNTO DE DADOS PARA O MODELO SE AJUSTAR AS SAZONALIDADES SEMESTRAIS E À ALTERNACIA DE SEMESTRES. AS FEATURES CATEGÓRICAS QUE INDICAM OS SEMESTRES E DIA DA SEMANA, BEM COM AS FEATURES QUE QUANTIFICAM RECESSOS (DISTANCIA REGISTRO ANTERIOR E POSTERIOR) TEM POTENCIAL DE AGREGAR APRENDIZADO NESSA QUESTÃO, MAS É NECESSÁRIO UMA DIVERSIFICAÇÃO MAIOR DO CONJUNTO DE DADOS POIS TREINAMOS APENAS COM 1 PERÍODO SAZONAL! (1 ANO PARA TREINO, 1 PARA VALIDAÇÃO E 1 PARA TESTE)\newline
        ACRESCENTAR FEATURES DE EVENTOS IMPORTANTES PARA IDENTIFICAR PARALISAÇÕES E EVENTOS DO TIPO.\newline
        UMA FEATURE DE CARDÁPIO TEM POTENCIAL DE AUMENTAR A QUALIDADE DA PREDIÇÃO\newline
        UMA FEATURE REPRESENTANDO O NÚMERO DE ALUNOS MATRICULADOS EM CADA PERÍODO DE CADA DIA DA SEMANA TEM GRANDE POTENCIAL DE AUMENTAR A PREDIÇÃO.\newline
        PESQUISAS PODEM SER FEITAS PARA UMA MELHOR TRANSFORMAÇÃO DOS DADOS DE ENTRADA NO MODELO PERCEPTRON POIS SÃO DADOS DISCRETOS, ENQUANTO OS DADOS QUE ENTRAM NA CAMADA GRU SÃO TEMPORAIS (COM INTERVALO DE 5 DIAS).\newline

    \section{Conclusões gerais}
         As análises diversas de previsão de demanda para o tema abordado requerem extensos métodos de implementação e estruturação de dados.
        Uma das etapas mais importantes do trabalho, é o método de coleta de dados. Muitos podem ser de acesso burocrático, ou de difícil busca. E são o requisito primordial para o inicio de qualquer análise.
        
         A diversidade de métodos de aprendizado de máquina é imensurável, e dentro de apenas uma análise, que é o treino com retropropagação, pode-se montar infinitas topologias diferentes com base na estrutura dos dados coletados. 
        As heurísticas sobre a definição de topologia apesar de diversas, não são determinísticas, e o processo requer análise exploratória, subjetiva e empírica sobre o tema e problema a ser abordado.
        
         Todavia foi notório a eficiência dos modelos de aprendizado de máquina em trabalhos relacionados à restaurantes universitários. 
        
         Como no ICT - Unifesp, não há qualquer modelo atual de previsão, e a falta de um modelo causa desperdício de alimentos e prejuízo ao restaurante, a abordagem dessa pesquisa e sua continuação com novos métodos após a conclusão deste trabalho torna-se viável.
  %\begin{itemize}
  %\item Contextualização e Motivação; 
  %\item Definição do problema; 
  %\item Justificativas;
  %\item Objetivos:  Geral e específicos;
  %\item Metodologia e
  %\item Organização do documento.
  %\end{itemize}

  %\subsection{Sobre os Títulos e Capítulos}

  %As demais subdivisões do texto (seções, subseções, etc) ... 

  %\subsubsection{Título de Subseção}
  %Veja aqui um exemplo de citaçao direta \cite{memoir}.


  % ----------------------------------------------------------
  % Capitulo com exemplos de comandos inseridos de arquivo externo 
  % ----------------------------------------------------------

  % ---
  % Capitulo de revisão de literatura
  % ---
  %\chapter{Revisão Bibliográfica}

  % ---
  %\section{Introdução}
  % ---

  % ---
  % primeiro capitulo de Resultados
  % ---
  %\chapter{Resultados}

  % ---
  % Finaliza a parte no bookmark do PDF, para que se inicie o bookmark na raiz
  % ---
  % ---

  % ---
  % Conclusão
  % ---

  % ----------------------------------------------------------
  % ELEMENTOS PÓS-TEXTUAIS
  % ----------------------------------------------------------
  %\postextual


  % ----------------------------------------------------------
  % Referências bibliográficas
  % ----------------------------------------------------------
  %\bibliographystyle{plain}
  \bibliography{references}

  % ----------------------------------------------------------
  % Glossário
  % ----------------------------------------------------------
  %
  % Consulte o manual da classe abntex2 para orientações sobre o glossário.
  %
  %\glossary

  % ----------------------------------------------------------
  % Apêndices
  % ----------------------------------------------------------

  % ---
  % Inicia os apêndices
  % ---
  %\begin{apendicesenv}

  % Imprime uma página indicando o início dos apêndices
  %\partapendices

  % ----------------------------------------------------------
  %\chapter{Título de Apêndice}
  % ----------------------------------------------------------


  % ----------------------------------------------------------
  %\chapter{Título do Apêndice}
  % ----------------------------------------------------------


  %\end{apendicesenv}
  % ---


  % ----------------------------------------------------------
  % Anexos
  % ----------------------------------------------------------
   % ----------------------------------------------------------
  % \chapter{Plano de atividades para o TCC II}
  % ----------------------------------------------------------
    \chapter{Anexos}
	\section{1a Fase Experimental}
	    \subsection{Pré-Processamento e treino dos modelos}
	        \url{https://colab.research.google.com/drive/1spSZDJk1EwK9UK-jfYbWinKEq0EEYIuM?usp=sharing}
	    \subsection{Importação e aplicação de métricas dos modelos}
	        \url{https://colab.research.google.com/drive/1vLx4TmsDy0jxVF0BFLng9XFdxgR_IAPL?usp=sharing}
	\section{2a Fase Experimental}
	    \subsection{Pré-Processamento e treino dos modelos}
	        \url{https://colab.research.google.com/drive/1U4pTAAzBQDS3s5LFZqK1-isa3pHJQ9D8?usp=sharing}
	    \subsection{Importação e aplicação de métricas dos modelos}
	        \url{https://colab.research.google.com/drive/1bBMTP9YQcy6sRNHZTr3NRSt1YCxJyu5t?usp=sharing}
  % ---
  % Inicia os anexos
  % ---
  %\begin{anexosenv}

  % Imprime uma página indicando o início dos anexos
  %\partanexos

  % ---
  %\chapter{Título do Anexo}
  % ---

  %\end{anexosenv}
    \bookmarksetup{startatroot}% 
  \end{document}